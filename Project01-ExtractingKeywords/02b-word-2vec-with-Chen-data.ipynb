{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Preprocessing News Data\n",
    "\n",
    "Goals:\n",
    " + clean & cut news texts and store as LineSentence format (readable by `word2vec`);\n",
    " + clean & store news texts as a .txt file for further dependency parsing, meanwhile, keeping a small sample of texts for testing codes (`stanfordcorenlp`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_path = '/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/sqlResult_vec2world.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 276: expected 3 fields, saw 4\\nSkipping line 801: expected 3 fields, saw 19\\nSkipping line 1194: expected 3 fields, saw 20\\nSkipping line 1253: expected 3 fields, saw 5\\nSkipping line 1329: expected 3 fields, saw 5\\nSkipping line 1385: expected 3 fields, saw 5\\nSkipping line 1547: expected 3 fields, saw 43\\nSkipping line 1688: expected 3 fields, saw 20\\nSkipping line 1733: expected 3 fields, saw 6\\nSkipping line 1832: expected 3 fields, saw 4\\nSkipping line 2650: expected 3 fields, saw 5\\nSkipping line 3015: expected 3 fields, saw 4\\nSkipping line 3398: expected 3 fields, saw 4\\nSkipping line 3549: expected 3 fields, saw 4\\nSkipping line 3735: expected 3 fields, saw 6\\nSkipping line 4295: expected 3 fields, saw 4\\nSkipping line 5255: expected 3 fields, saw 5\\nSkipping line 5427: expected 3 fields, saw 4\\nSkipping line 5690: expected 3 fields, saw 7\\nSkipping line 5732: expected 3 fields, saw 4\\nSkipping line 5752: expected 3 fields, saw 4\\nSkipping line 5758: expected 3 fields, saw 4\\nSkipping line 5811: expected 3 fields, saw 4\\nSkipping line 5967: expected 3 fields, saw 8\\nSkipping line 6661: expected 3 fields, saw 4\\nSkipping line 6667: expected 3 fields, saw 4\\nSkipping line 7058: expected 3 fields, saw 7\\nSkipping line 7543: expected 3 fields, saw 92\\nSkipping line 7576: expected 3 fields, saw 82\\nSkipping line 7618: expected 3 fields, saw 10\\nSkipping line 7637: expected 3 fields, saw 7\\nSkipping line 7861: expected 3 fields, saw 4\\nSkipping line 7901: expected 3 fields, saw 4\\nSkipping line 8033: expected 3 fields, saw 15\\nSkipping line 8084: expected 3 fields, saw 4\\nSkipping line 8202: expected 3 fields, saw 4\\nSkipping line 8206: expected 3 fields, saw 5\\nSkipping line 8316: expected 3 fields, saw 4\\nSkipping line 8324: expected 3 fields, saw 7\\nSkipping line 8359: expected 3 fields, saw 6\\nSkipping line 8599: expected 3 fields, saw 9\\nSkipping line 8714: expected 3 fields, saw 12\\nSkipping line 8741: expected 3 fields, saw 10\\nSkipping line 8755: expected 3 fields, saw 92\\nSkipping line 8800: expected 3 fields, saw 4\\nSkipping line 8819: expected 3 fields, saw 154\\nSkipping line 8832: expected 3 fields, saw 4\\nSkipping line 8928: expected 3 fields, saw 9\\nSkipping line 9024: expected 3 fields, saw 4\\nSkipping line 9033: expected 3 fields, saw 5\\nSkipping line 9094: expected 3 fields, saw 4\\nSkipping line 9264: expected 3 fields, saw 4\\nSkipping line 9449: expected 3 fields, saw 4\\nSkipping line 9717: expected 3 fields, saw 5\\nSkipping line 10190: expected 3 fields, saw 4\\nSkipping line 10271: expected 3 fields, saw 4\\nSkipping line 10859: expected 3 fields, saw 28\\nSkipping line 11388: expected 3 fields, saw 4\\nSkipping line 11425: expected 3 fields, saw 4\\nSkipping line 11612: expected 3 fields, saw 15\\nSkipping line 12114: expected 3 fields, saw 4\\nSkipping line 12115: expected 3 fields, saw 15\\nSkipping line 12116: expected 3 fields, saw 4\\nSkipping line 12125: expected 3 fields, saw 7\\nSkipping line 12126: expected 3 fields, saw 10\\nSkipping line 12127: expected 3 fields, saw 5\\nSkipping line 12734: expected 3 fields, saw 5\\nSkipping line 12735: expected 3 fields, saw 18\\nSkipping line 12736: expected 3 fields, saw 7\\nSkipping line 13446: expected 3 fields, saw 9\\nSkipping line 13619: expected 3 fields, saw 4\\nSkipping line 14436: expected 3 fields, saw 4\\nSkipping line 14545: expected 3 fields, saw 10\\nSkipping line 14546: expected 3 fields, saw 9\\nSkipping line 14547: expected 3 fields, saw 6\\nSkipping line 14548: expected 3 fields, saw 4\\nSkipping line 14549: expected 3 fields, saw 13\\nSkipping line 14550: expected 3 fields, saw 16\\nSkipping line 15290: expected 3 fields, saw 6\\nSkipping line 18116: expected 3 fields, saw 6\\nSkipping line 18486: expected 3 fields, saw 7\\nSkipping line 18665: expected 3 fields, saw 7\\nSkipping line 19476: expected 3 fields, saw 7\\nSkipping line 34045: expected 3 fields, saw 5\\nSkipping line 42296: expected 3 fields, saw 4\\nSkipping line 48454: expected 3 fields, saw 4\\nSkipping line 49541: expected 3 fields, saw 4\\nSkipping line 59249: expected 3 fields, saw 4\\nSkipping line 61933: expected 3 fields, saw 4\\nSkipping line 82047: expected 3 fields, saw 4\\nSkipping line 82954: expected 3 fields, saw 5\\nSkipping line 90485: expected 3 fields, saw 4\\nSkipping line 91251: expected 3 fields, saw 4\\nSkipping line 96294: expected 3 fields, saw 4\\nSkipping line 97032: expected 3 fields, saw 5\\nSkipping line 98725: expected 3 fields, saw 4\\nSkipping line 99613: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "# read in news content, skipping bad lines\n",
    "news_df = pd.read_csv(csv_path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>3183</td>\n",
       "      <td>你的脸，就是你的性格与福报！</td>\n",
       "      <td>01我一直喜欢看某卫视的相亲节目，关注的却并非谁牵手了谁有没有修成正果，而且那一张张来来去去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49843</th>\n",
       "      <td>39231</td>\n",
       "      <td>[2]（外代二线）斯里兰卡庆新年</td>\n",
       "      <td>新华社照片，外代，2017年4月24日\\n（外代二线）斯里兰卡庆新年\\n4月23日，在斯里兰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24804</th>\n",
       "      <td>14188</td>\n",
       "      <td>（港澳台·财经观察）香港业界各就各位热盼深港通开通</td>\n",
       "      <td>新华社香港１１月２５日电（记者战艳　董方奇）１１月初以来，香港各界频频举办各种活动，为迎...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>74307</td>\n",
       "      <td>[1]（外代二线）买斋灯备斋月</td>\n",
       "      <td>新华社照片，外代，2017年5月25日\\n（外代二线）买斋灯备斋月\\n5月24日，在埃及开罗...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51337</th>\n",
       "      <td>40725</td>\n",
       "      <td>上海银行拟非公开发行2亿优先股补充资本金</td>\n",
       "      <td>\\n新华社上海4月25日新媒体专电（记者桑彤）创下2016年最大规模IPO的上海银行，24日...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                      title  \\\n",
       "3167    3183             你的脸，就是你的性格与福报！   \n",
       "49843  39231           [2]（外代二线）斯里兰卡庆新年   \n",
       "24804  14188  （港澳台·财经观察）香港业界各就各位热盼深港通开通   \n",
       "84915  74307            [1]（外代二线）买斋灯备斋月   \n",
       "51337  40725       上海银行拟非公开发行2亿优先股补充资本金   \n",
       "\n",
       "                                                 content  \n",
       "3167   01我一直喜欢看某卫视的相亲节目，关注的却并非谁牵手了谁有没有修成正果，而且那一张张来来去去...  \n",
       "49843  新华社照片，外代，2017年4月24日\\n（外代二线）斯里兰卡庆新年\\n4月23日，在斯里兰...  \n",
       "24804  　　新华社香港１１月２５日电（记者战艳　董方奇）１１月初以来，香港各界频频举办各种活动，为迎...  \n",
       "84915  新华社照片，外代，2017年5月25日\\n（外代二线）买斋灯备斋月\\n5月24日，在埃及开罗...  \n",
       "51337  \\n新华社上海4月25日新媒体专电（记者桑彤）创下2016年最大规模IPO的上海银行，24日...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "news_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_original = news_df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to clean the strings and cut to words\n",
    "\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "def cut(string): return ' '.join(jieba.cut(string))\n",
    "def token(string):\n",
    "    return re.findall(r'[\\d|\\w]+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [token(str(n)) for n in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the sentences together in each article\n",
    "content = [' '.join(n) for n in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['图集简介 由玩家shishioh带来的真骨雕假面骑士亚马逊的评测图集 这款真骨雕假面骑士亚马逊以通贩的形式贩售 配件不算丰富 只有8个手型 2个披风替换件和2个腰带替换件 图片转自shishioh 侵删',\n",
       " '现如今随着各大赛区2019年新赛季的接近 各位职业选手为了尽快调整好自己的状态也是纷纷开始了自己的冲分之旅 比如像SN的新打野选手就冲到了韩服第二名 而像rookie jackeylove等上分如喝水选手也是重回韩服高分段 可是就在这种大背景下 一名职业选手最近却是遨游黑铁段位 甚至还遭到了队友的无情嘲讽 这到底是怎么一回事呢 事情的主人公还是我们的锅老师 由于新赛季段位重置的缘故 mlxg在国服的账号经过了九胜一负的排位赛之后竟然只定位到了黑铁四 其实作为一名职业选手来说 mlxg原本在韩服的排位分数并不出众 钻石打野王 的称号也不是空穴来风 但是谁曾想到 mlxg竟然还有沦落到黑铁段位的时候 不过mlxg对于自己这个段位还是非常看得开的 在每局游戏开始的时候还会非常调皮的发一些能够让所有人都看到的骚话 比如什么 大家好 请叫我黑铁打野王 不过很明显 并不是所有的队友都会给mlxg好脸色 比如下面的这名玩家 在某局游戏的开始 mlxg再次非常调皮的发送了一句 各位大哥大姐 求求你们带我上个青铜吧 可是这时一名队友却突然毫不客气的回复道 爷不想带你 确实 由于mlxg隐藏分太高的缘故 这几天匹配到的队友都是钻石的 大神 对于一名钻石段位的玩家来说 去带一名黑铁的萌新的确是一件既丢份又浪费时间的事情 不过虽然被队友怼了 但是mlxg的做法却是非常的正确 既然你不想带我 那么就让我来带你吧 最终在mlxg的carry下 这名回怼mlxg的玩家也是几乎以躺赢的姿态结束了这局游戏 可能这名玩家现在也正在为自己与一位真正大神发生矛盾而后悔不已吧 而经过自己的努力 mlxg在这两天也是终于晋级青铜分段 看来 黑铁打野王 的称号已经不适用了啊 各位同学 你们觉得青铜段位的锅老师应该叫什么样的外号呢',\n",
       " '引言 Rookie撞脸肖央 当dopa和小沈阳同框出现 网友笑了 作为知名的英雄联盟职业选手 rookie等了这个全球总冠军很久 而在这次的s8全球总决赛上 IG终于拿到了LPL赛区八年来的第一个冠军 拿到冠军后 网友却突然发现rookie为什么这么像娱乐圈中的一位明星肖央了 其实撞脸的事情在我们的生活之中常常出现 就连马云都曾经被撞脸过 而近日有网友在观看dopa的直播的时候发现他居然在搜索小沈阳 这是怎么回事了 作为一名韩国的知名主播 曾经的英雄联盟职业选手 他的技术水平也是十分的不错的 而这次他之所以搜索小沈阳 是因为他在直播的时候 被网友说道和小沈阳很像 虽然他当他看到小沈阳的时候说和自己不像 其实明眼的人都能够看出来 同框的两人像不像 在生活中总是有很多有趣的撞脸的事情 不知道你还知道哪些撞脸的人了 对此你怎么看了 Rookie撞脸肖央 当dopa和小沈阳同框出现 网友笑了',\n",
       " '2019年的开始 对LOL职业选手来说 可以说是一个好的开始 因为他们终于迎来了一年来最难得的休赛期 于是各选手每天都开始了自己的直播之旅 特别是Uzi 这两天在峡谷之巅的排位可以说是玩的不亦乐乎 细心的玩家则是发现 最近Uzi这么勤快直播的原因也在于 接下来他马上要参加虎牙星盛典的LOL全明星赛 不过今天Uzi直播的时候 无意间透露了他的按键习惯 表示自己的用中指按A键 这个消息出来后 不少玩家都有些懵逼 A键原来还能这样玩的 还有网友调侃道 这样岂不是Uzi每次他A人的时候 都是在朝人竖中指 哈哈哈哈 不得不说 这个确实是挺奇葩的 大多数应该用的是无名指吧 少数用小拇指 中指的更是少之又少 于是不少玩家就会发现 其实很多职业选手在键位设置下 也是一个比一个奇葩 Uzi的键位设置相对来说 是最原始的LOL设置 没有太多的改动 反而是Uzi的队友MLXG的键位 可以说是LOL中的第一人 为什么这么说呢 因为MLXG的键位设置 你根本就看不到他具体的键位设置 全都是空白 不显示的 根据网友的测试 原来MLXG是利用快捷施法和智能施法这两个的功能将面板的键位隐藏了起来 估计是MLXG不想让别人看到他的键位习惯吧 于是也有玩家调侃道 这职业选手的键位设置 真的是一个比一个奇葩啊 看完正常的Uzi键位后 再来看看马哥的键位设置 你会发现马哥也是会玩 不过根据马哥粉丝解释 这个键位设置是马哥最开始玩游戏留下来的习惯 因此都没有改动过 这样看来的话 还是Uzi的键位最为正常啊 当然 除了他用中指按A键外 不得不说 Uzi和韦神这两个选手 最近玩LOL是真的勤快 抛开Uzi不说 韦神昨天更是连绝地求生都不玩 跑到了峡谷之巅练英雄 还练到了凌晨三点多 看来这次为了虎牙星盛典的LOL全明星赛 Uzi和韦神都是非常重视的啊 期待1月5日他们俩的 猪狗大战',\n",
       " '新的一年已经到来了 在过去的一年中LOL上线了许多款精美皮肤 各种系列层出不穷 小伙伴们的钱包都xxx 但很多人都说 上新的速度太快在质量方面就不能保证 而拳头似乎也意识到了这个问题 在前几天开始收集起来大家的意见 下面 村长就来给大家盘点一下在2018年新出的皮肤当中 最不受欢迎的几款皮肤 睡衣守护者 露露这款皮肤可以说是完完全全的照骗 看着原画上的露露非常温柔可爱 但是进入游戏之后 会发现这和原画相比根本就不是一个人 偏绿色的配色也不是那么讨喜 加上背上的翅膀 看久了会发现特别像苍蝇 同时和睡衣系列的其他人比起来 在特效上简直差的不行 仔细看你会发现和原皮没有多大区别 致胜金靴要说2018年最不受玩家待见的皮肤 那么李青的这款致胜金靴是当之无愧的第一名 大家要知道 不管是在什么服务器里 喜欢李青的玩家都很多 能秀伤害高 加上龙瞎的存在可以说李青一直都是很帅气的角色 但是在出了这款皮肤过后 有人直言简直毁了这个英雄 手感差不说 Q技能的弹道非常奇怪 模型在游戏中看着也很丑陋 说白了就是在原皮的基础上换了衣服和发型 入手了这款皮肤的玩家都直呼要拳头退钱 源代码娜美源代码这个系列在玩家心里评价都还不错 从最早星妈和丽桑卓开始出现 到后来的卡密尔都算比较新颖的设计 在今年由于各种原因 本来打算上架商城的源代码娜美直接赠送给玩家 但当皮肤到手之后 能免费送皮肤虽然还不错 但是不管是原画还是模型都非常丑陋 技能特效上更是看不懂的设计 很多小姐姐们宁愿用原皮都不愿意用这款皮肤 就能知道她的设计有多差 总的来说 在2018年中还是推出了不少精美的皮肤 不管是从模型上还是技能特效上都和之前有了很大的变化 但这几款皮肤却是里面的败笔 小伙伴们觉得还有哪些皮肤不好看呢 一起来说说吧']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/1y/1btp7xpj7b1f82lnwvn2916h0000gn/T/jieba.cache\n",
      "Loading model cost 0.833 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# then cut into words\n",
    "content = [cut(n) for n in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as the Linesentence format readable by gensim word2vec\n",
    "with open('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-sentences-cut.txt', 'w') as f:\n",
    "    for n in content:\n",
    "        f.write(n + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanwhile, we want to keep a copy of the news content with quotation marks\n",
    "# for further depedency parsing and quotes extraction\n",
    "\n",
    "content_original = news_df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100214"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content_original[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-original.txt', 'w') as f:\n",
    "    for n in content_original: \n",
    "        f.write(str(n) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【图集简介】 由玩家shishioh带来的真骨雕假面骑士亚马逊的评测图集，这款真骨雕假面骑士亚马逊以通贩的形式贩售，配件不算丰富，只有8个手型、2个披风替换件和2个腰带替换件。图片转自shishioh，侵删。',\n",
       " '现如今随着各大赛区2019年新赛季的接近，各位职业选手为了尽快调整好自己的状态也是纷纷开始了自己的冲分之旅，比如像SN的新打野选手就冲到了韩服第二名，而像rookie、jackeylove等上分如喝水选手也是重回韩服高分段，可是就在这种大背景下，一名职业选手最近却是遨游黑铁段位，甚至还遭到了队友的无情嘲讽，这到底是怎么一回事呢？事情的主人公还是我们的锅老师，由于新赛季段位重置的缘故，mlxg在国服的账号经过了九胜一负的排位赛之后竟然只定位到了黑铁四，其实作为一名职业选手来说，mlxg原本在韩服的排位分数并不出众，“钻石打野王”的称号也不是空穴来风。但是谁曾想到，mlxg竟然还有沦落到黑铁段位的时候。不过mlxg对于自己这个段位还是非常看得开的，在每局游戏开始的时候还会非常调皮的发一些能够让所有人都看到的骚话，比如什么“大家好，请叫我黑铁打野王”。不过很明显，并不是所有的队友都会给mlxg好脸色，比如下面的这名玩家。在某局游戏的开始，mlxg再次非常调皮的发送了一句“各位大哥大姐，求求你们带我上个青铜吧”，可是这时一名队友却突然毫不客气的回复道：“爷不想带你”。确实，由于mlxg隐藏分太高的缘故，这几天匹配到的队友都是钻石的“大神”，对于一名钻石段位的玩家来说，去带一名黑铁的萌新的确是一件既丢份又浪费时间的事情。不过虽然被队友怼了，但是mlxg的做法却是非常的正确，既然你不想带我，那么就让我来带你吧。最终在mlxg的carry下，这名回怼mlxg的玩家也是几乎以躺赢的姿态结束了这局游戏，可能这名玩家现在也正在为自己与一位真正大神发生矛盾而后悔不已吧。而经过自己的努力，mlxg在这两天也是终于晋级青铜分段，看来“黑铁打野王”的称号已经不适用了啊，各位同学，你们觉得青铜段位的锅老师应该叫什么样的外号呢？',\n",
       " '引言：Rookie撞脸肖央？当dopa和小沈阳同框出现，网友笑了！作为知名的英雄联盟职业选手，rookie等了这个全球总冠军很久，而在这次的s8全球总决赛上，IG终于拿到了LPL赛区八年来的第一个冠军。拿到冠军后，网友却突然发现rookie为什么这么像娱乐圈中的一位明星肖央了？其实撞脸的事情在我们的生活之中常常出现，就连马云都曾经被撞脸过。而近日有网友在观看dopa的直播的时候发现他居然在搜索小沈阳，这是怎么回事了？作为一名韩国的知名主播，曾经的英雄联盟职业选手，他的技术水平也是十分的不错的。而这次他之所以搜索小沈阳，是因为他在直播的时候，被网友说道和小沈阳很像。虽然他当他看到小沈阳的时候说和自己不像，其实明眼的人都能够看出来，同框的两人像不像。在生活中总是有很多有趣的撞脸的事情，不知道你还知道哪些撞脸的人了？对此你怎么看了？Rookie撞脸肖央？当dopa和小沈阳同框出现，网友笑了！',\n",
       " '2019年的开始，对LOL职业选手来说，可以说是一个好的开始！因为他们终于迎来了一年来最难得的休赛期，于是各选手每天都开始了自己的直播之旅，特别是Uzi，这两天在峡谷之巅的排位可以说是玩的不亦乐乎！细心的玩家则是发现，最近Uzi这么勤快直播的原因也在于：接下来他马上要参加虎牙星盛典的LOL全明星赛！不过今天Uzi直播的时候，无意间透露了他的按键习惯，表示自己的用中指按A键！这个消息出来后，不少玩家都有些懵逼，A键原来还能这样玩的？还有网友调侃道：这样岂不是Uzi每次他A人的时候，都是在朝人竖中指，哈哈哈哈。不得不说，这个确实是挺奇葩的，大多数应该用的是无名指吧，少数用小拇指，中指的更是少之又少！于是不少玩家就会发现，其实很多职业选手在键位设置下，也是一个比一个奇葩！Uzi的键位设置相对来说，是最原始的LOL设置，没有太多的改动，反而是Uzi的队友MLXG的键位，可以说是LOL中的第一人！为什么这么说呢？因为MLXG的键位设置，你根本就看不到他具体的键位设置，全都是空白，不显示的！根据网友的测试，原来MLXG是利用快捷施法和智能施法这两个的功能将面板的键位隐藏了起来，估计是MLXG不想让别人看到他的键位习惯吧！于是也有玩家调侃道：这职业选手的键位设置，真的是一个比一个奇葩啊！看完正常的Uzi键位后，再来看看马哥的键位设置，你会发现马哥也是会玩！不过根据马哥粉丝解释，这个键位设置是马哥最开始玩游戏留下来的习惯，因此都没有改动过。这样看来的话，还是Uzi的键位最为正常啊（当然，除了他用中指按A键外）！不得不说，Uzi和韦神这两个选手，最近玩LOL是真的勤快！抛开Uzi不说，韦神昨天更是连绝地求生都不玩，跑到了峡谷之巅练英雄，还练到了凌晨三点多。看来这次为了虎牙星盛典的LOL全明星赛，Uzi和韦神都是非常重视的啊，期待1月5日他们俩的“猪狗大战”！',\n",
       " '新的一年已经到来了，在过去的一年中LOL上线了许多款精美皮肤。各种系列层出不穷，小伙伴们的钱包都xxx。但很多人都说，上新的速度太快在质量方面就不能保证，而拳头似乎也意识到了这个问题，在前几天开始收集起来大家的意见。下面，村长就来给大家盘点一下在2018年新出的皮肤当中，最不受欢迎的几款皮肤。睡衣守护者 露露这款皮肤可以说是完完全全的照骗\"！看着原画上的露露非常温柔可爱。但是进入游戏之后，会发现这和原画相比根本就不是一个人，偏绿色的配色也不是那么讨喜。加上背上的翅膀，看久了会发现特别像苍蝇。同时和睡衣系列的其他人比起来，在特效上简直差的不行，仔细看你会发现和原皮没有多大区别。致胜金靴要说2018年最不受玩家待见的皮肤，那么李青的这款致胜金靴是当之无愧的第一名。大家要知道，不管是在什么服务器里，喜欢李青的玩家都很多，能秀伤害高，加上龙瞎的存在可以说李青一直都是很帅气的角色。但是在出了这款皮肤过后，有人直言简直毁了这个英雄。手感差不说，Q技能的弹道非常奇怪，模型在游戏中看着也很丑陋，说白了就是在原皮的基础上换了衣服和发型，入手了这款皮肤的玩家都直呼要拳头退钱！源代码娜美源代码这个系列在玩家心里评价都还不错，从最早星妈和丽桑卓开始出现，到后来的卡密尔都算比较新颖的设计。在今年由于各种原因，本来打算上架商城的源代码娜美直接赠送给玩家。但当皮肤到手之后，能免费送皮肤虽然还不错，但是不管是原画还是模型都非常丑陋，技能特效上更是看不懂的设计。很多小姐姐们宁愿用原皮都不愿意用这款皮肤，就能知道她的设计有多差。总的来说，在2018年中还是推出了不少精美的皮肤，不管是从模型上还是技能特效上都和之前有了很大的变化。但这几款皮肤却是里面的败笔，小伙伴们觉得还有哪些皮肤不好看呢？一起来说说吧！\"']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_original[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a small sample for testing codes\n",
    "with open('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-sample.txt', 'w') as f:\n",
    "    for n in content_original[1:15]:\n",
    "        f.write(str(n) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Word2Vec & Getting a List of Similar Words to \"说\"\n",
    "Goals:\n",
    " + 1) implement a word2vec model & get the word vectors;\n",
    " + 2) find the most similar 250 words to \"说\";\n",
    " + 3) using `pos` tags to filter out the non-verbs in the list obtained from 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-sentences-cut.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_word2vec = Word2Vec(LineSentence(file_path),\n",
    "                         sg=0, min_count=10, size=100, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model & word vectors\n",
    "\n",
    "news_word2vec.save('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-model')\n",
    "\n",
    "vectors_path = '/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/nlp-project01/vec2world-news-model-word-vec.bin'\n",
    "word_vectors = news_word2vec.wv\n",
    "word_vectors.save_word2vec_format(vectors_path, binary=True)\n",
    "\n",
    "# to load binary word vectors into a model from a local directory, use the following:\n",
    "#from gensim.models import KeyedVectors\n",
    "#model = KeyedVectors.load_word2vec_format('path/to/<file_name>.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('表示', 0.8180868625640869),\n",
       " ('指出', 0.7621641755104065),\n",
       " ('认为', 0.7583377361297607),\n",
       " ('坦言', 0.7102848887443542),\n",
       " ('告诉', 0.7093005180358887),\n",
       " ('明说', 0.6813331842422485),\n",
       " ('看来', 0.6698801517486572),\n",
       " ('称', 0.6478279829025269),\n",
       " ('文说', 0.6302861571311951),\n",
       " ('强调', 0.608858585357666),\n",
       " ('地说', 0.5898992419242859),\n",
       " ('介绍', 0.5855918526649475),\n",
       " ('所说', 0.5743290185928345),\n",
       " ('中说', 0.5716768503189087),\n",
       " ('透露', 0.5598751306533813),\n",
       " ('说道', 0.5584741234779358),\n",
       " ('时说', 0.5447806119918823),\n",
       " ('承认', 0.5331262946128845),\n",
       " ('提到', 0.5205406546592712),\n",
       " ('问', 0.5078859329223633)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word2vec.most_similar('说', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5205407"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word2vec.similarity('说', '提到')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_related_words(init_words, model, max_size, top_n):\n",
    "    \"\"\"\n",
    "    @ init_words: the initial words whose synonyms we want to search for\n",
    "    @ model: the word2vec model\n",
    "    @ max_size: the size limit for 'seen' to reduce the searching space\n",
    "    @ top_n: the number of top similar words\n",
    "    \"\"\"\n",
    "    unseen_list = init_words\n",
    "    \n",
    "    seen = defaultdict(int)\n",
    "    \n",
    "    # Init sub nodes dict\n",
    "    sub_nodes_dic = defaultdict(list)\n",
    "    \n",
    "    while unseen_list and len(seen) < max_size:\n",
    "        \n",
    "        node = unseen_list.pop(0)\n",
    "        \n",
    "        # Get sub nodes directly if in dict\n",
    "        if node in sub_nodes_dic:\n",
    "            sub_nodes = sub_nodes_dic[node]\n",
    "        \n",
    "        else:\n",
    "            # Get top_n similar words for first word by word2vec model\n",
    "            sub_nodes = [w for w, s in model.most_similar(node, topn=top_n)]\n",
    "            \n",
    "            # Save result to sub nodes dict\n",
    "            sub_nodes_dic[node] = sub_nodes\n",
    "        \n",
    "        # Add similar words result to unseen words list\n",
    "        unseen_list += sub_nodes\n",
    "        \n",
    "        # Save current seen word and increase 1 weight\n",
    "        seen[node] += 1 \n",
    "    \n",
    "    # revise the word weights by multiplying the similarity value from the word2vec model\n",
    "    for word, value in seen.items():        \n",
    "            weight = model.similarity(init_words[0], word)\n",
    "            seen[word] = value * weight\n",
    "    \n",
    "    # sort seen words dict by words weight\n",
    "    seen_rank = sorted(seen.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [w for w, s in seen_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:40: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    }
   ],
   "source": [
    "related_words = get_related_words(['说','表示'], news_word2vec, max_size=1000, top_n=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['明说', '所指', '深有体会', '因斯', '问过', '地说', '坚称', '介绍', '董', '说道', '声称', '坦承', '名誉', '如是说', '否认', '交代', '文说', '留意到', '纳说', '申明', '对瓦姆', '称', '所说', '解释', '告诉', '伯斯', '说', '知情', '透露', '却说', '劝', '常务', '特别感谢', '红霞', '说法', '道', '直言', '叮嘱', '自称', '表示', '辩称', '资深', '提醒', '科说', '翃', '秘书', '推测', '得知', '称赞', '回答', '写道', '别有用心', '打听', '批评', '承认', '并不知道', '及其', '请问', '纷纷表示', '研究室', '罗说', '反驳', '夸赞', '置评', '出面', '埃里克', '告诫', '怀疑', '中称', '澄清', '海涛', '大发雷霆', '抨击', '思思', '求证', '称呼', '国利', '镐', '坦言', '闭上眼睛', '感叹', '斯说', '助理', '翻看', '深有感触', '抱怨', '警告', '离职', '建议', '宣称', '担心', '知晓', '浪潮集团', '回击', '指责', '教过', '追究责任', '口中', '部副', '洪说', '事务所', '主管', '正想', '出席会议', '感慨', '特别强调', '还称', '证实', '首席', '时称', '担任', '祁', '供图', '化验员', '请教', '提到', '兼任', '徐海', '代理', '询问', '对此', '侃侃而谈', '表示感谢', '问起', '某林', '不感兴趣', '法务', '认定', '反问', '兼', '认为', '佩服', '平说', '加恩', '发给', '金说', '说出', '热罗姆', '明哲', '质疑', '欢喜', '现任', '指认', '志强', '中说', '政务司', '转达', '海波', '立国', '胡说八道', '美国康奈尔大学', '描述', '提及', '回应', '童岚', '严格要求', '责怪', '公开批评', '颜之宏', '执行局', '清楚', '建华', '同性恋', '发推', '指出', '问道', '诉', '猜测', '德昌', '埃斯', '具名', '卫东', '任命', '国家税务总局', '通讯员', '行政院', '职位', '并称', '阿姨', '何', '李', '爱华', '洪涛', '直言不讳', '副乡长', '赵', '听说', '宁宁', '武', '董华', '我怕', '谈起', '戈德', '奉劝', '苏禄东', '茶坊', '玉林', '评价', '年近古稀', '东升', '现义', '表态', '议院', '特聘', '市场策略', '原话', '红运', '一峰', '保国', '艳红', '志豪', '深知', '浩', '赞同', '志峰', '立新', '写信给', '国务院台办', '温', '彩霞', '嘱咐', '感谢', '详解', '尕', '看法', '志军', '歧视性', '崔静', '个体户', '鹏飞', '劲松', '晨光', '提说', '卫国', '宝林', '刘', '松涛', '武说', '执行', '承担责任', '当过', '茂林', '荣华', '建军', '赞扬', '中国外交部', '永华', '青峰', '振声', '良善', '引述', '永年', '浠水县', '深表', '璎珞', '肖', '获悉', '聊起', '赞不绝口', '成文', '问', '德顺', '黄鹤', '志远', '春华', '冬冬', '博雅', '要求', '给出', '崔', '晶晶', '福海', '侯', '推断', '三子', '庄子', '吴', '颖川', '艳霞', '何晓彤', '利洛夫', '同意', '苗苗', '暘', '老先生', '质问', '地问', '婷婷', '党委委员', '南平市', '伟民', '室主任', '原副', '靖宇', '以为', '林园', '江华', '曹', '王', '口镇', '邓', '执行官', '供认', '出任', '师班农', '老支书', '永', '春晖', '政治处', '沈梦辰', '幕僚长', '所提', '党组书记', '小林', '推断出', '财政司', '固镇', '涌泉', '总监制', '事务部', '专程到', '新安', '田', '春生', '盛赞', '感触', '翟', '昭觉', '暗示', '部长', '殷家', '晋华', '岳', '提议', '看来', '滔滔不绝', '郭', '嘲笑', '敦促', '估计', '大千', '强调指出', '高度评价', '高级技师', '木业', '咨询', '树文', '顾问', '桂平', '张阳', '调侃', '国台办', '回访', '主任', '历数', '帮忙', '冉冉', '眼里', '张侨', '眼中', '知之甚少', '做主', '陈', '市委常委', '吕', '替', '疑惑', '志成', '河村', '发问', '局长', '谴责', '邵', '南平', '农艺师', '计划处', '肿瘤医院', '觉得', '洪洞县', '拜访', '阆中市', '拨通', '临洮县', '听到', '商务部长', '登峰', '永康', '陆', '告知', '接受', '管理处', '递给', '翔', '斯派', '承', '事业部', '王丽', '急诊科', '华宁', '恳请', '瀛', '掏腰包', '里亚布', '萧永航', '国际电信联盟', '亲眼看到', '省农业厅', '考虑一下', '一席话', '娄辰', '局原', '布勒', '答应', '孝顺', '特说', '司', '沟镇', '嘲讽', '不以为然', '毛伟豪', '袁桐利', '谢樱', '信得过', '二排', '叫', '中国艺术研究院', '破口大骂', '华商报', '决定', '招呼', '讳言', '市场部', '省林业厅', '评述', '姜宁', '看望', '郭敬丹', '直呼', '研究部', '伯乐', '崇文', '写给', '所述', '著文', '认识', '陆慷说', '娶', '持', '笑称', '聊到', '赵克志', '常务副', '北京大学国际关系学院', '科技日报', '奇文', '查阅', '巍巍', '口腔医院', '获知', '所称', '余霜', '每经', '深信不疑', '农办', '克说', '卡纳', '锦', '言论', '省卫', '谈论', '高博', '介入', '黄渤', '自称为', '寄给', '国务院台湾事务办公室', '俄总统', '徐国', '主持会议', '开玩笑', '致信', '罗岗', '亲历', '开店', '待见', '敬佩', '张玥', '觉得很有', '听闻', '会面', '法律顾问', '这令', '英说', '益', '经信委', '应邀出席', '先给', '干涉', '刁难', '人事变动', '客座', '吴文诩', '表述', '刘奕湛', '驻京办', '念念不忘', '恩师', '后悔', '代代传', '发现自己', '说不出', '本报讯', '刘帅', '宽慰', '援引', '见习', '杨迪', '荣光', '说错', '利益冲突', '行长', '周强', '董小红', '回忆', '安慰', '那会儿', '劝告', '回忆起', '感到', '董瑞丰', '访美', '南方周末', '点评', '李骥志', '报告书', '知道', '商谈', '庆幸', '沈忠浩', '深爱着', '致电', '严', '北青报', '顾忌', '振国', '粤羽', '国务院发展研究中心', '陈晨', '访英', '专长', '感激', '初到', '拆弹', '郭爽', '黄浩苑', '鼓掌', '出差', '曼说', '帮', '妨碍', '来过', '形容', '环评', '解雇', '白靖利', '惩罚', '理由', '科技司', '心知肚明', '结识', '公关', '开会讨论', '贬低', '曾称', '拍戏', '提问', '科技委', '现场采访', '迷上', '披露', '奢求', '特殊性', '理解', '尼玛', '误以为', '为所欲为', '向定杰', '社会科学院', '反复强调', '冯俊伟摄', '这句', '决算', '猜', '外交部长', '学过', '林凯', '排斥', '做过', '事务', '周效政', '李晓渝', '依据', '耳闻', '财政部长', '娓娓', '新文化', '民法学', '德说', '政和', '身为', '盖博铭', '检讨', '任军', '赵珺', '宣布', '费根', '郑钧天', '鲁金博', '孔祥鑫', '张玉洁', '讲讲', '说明', '观战', '估算', '赵宇飞', '分析', '下定决心', '一句', '李华', '说会', '谈谈', '刘良恒', '发现', '意料', '领奖', '疑虑', '想法', '史林静', '取悦', '看得出来', '穆序', '苗壮', '演', '看作', '分身乏术', '说实话', '国际金融报', '初来乍到', '猜想', '管理司', '听过', '刘阳', '提', '记得', '说真的', '非常重视', '观点', '美国商务部', '耳熟能详', '当有', '尼说', '视而不见', '反思', '剧荒', '表达', '欣喜', '邹乐', '极力推荐', '意图', '做生意', '称作', '看出', '不在乎', '想必', '重申', '聊过', '吐槽', '黄超', '无视', '聊', '听取', '力挺', '想起', '地向', '肖娟', '董璐', '引用', '王念', '一去不复返', '艺术界', '具体内容', '原因', '张隽玮', '黄堃', '见到', '做法', '标榜', '想过', '列举', '内政', '的话', '德国政府', '据悉', '潘旭摄', '自我介绍', '帮不了', '赵阳', '伊琳娜', '委副', '出乎', '强调', '称之为', '议政', '负责', '十分重视', '周科', '结论', '反省', '刘莉莉', '苦不堪言', '一再', '报答', '接手', '考虑', '丁林摄', '心路历程', '德国联邦', '想想', '坚说', '判断', '看过', '反应', '董峻', '反之', '李骥志摄', '刘颖摄', '力推', '访华', '预言', '乐见', '引热议', '李安摄', '裘立华', '解读', '想像', '秦晴摄', '甘为', '玢', '看得出', '江文耀摄', '了解', '黄勇贤摄', '易爱军', '丁旭摄', '不难看出', '讲', '熟悉', '说服', '否定', '不谈', '柳丝', '论证', '唐奕摄', '有关', '其实', '王博摄', '党琦', '马宁摄', '王晔摄', '王优玲', '石志勇', '樊曦', '汪平摄', '选车', '林宏摄', '聊聊', '为此', '深感', '李仁虎', '俞俭', '忽略不计', '李佳', '执笔', '研判', '见过', '保密', '矛盾重重', '潘革平', '呼吁', '越通社', '跟队', '主持', '明确', '极力', '呈交', '显示', '顾及', '明白', '周华摄', '在我看来', '至于', '古稀之年', '磨练', '冯武', '相反', '此外', '针对', '独到', '涉华', '一说', '是因为', '为何', '总结', '上称', '说起', '鞠焕宗摄', '认同', '祝', '专家建议', '李震摄', '明确指出', '共见', '杨青摄', '栾海', '外交事务', '反感', '尚无', '所在', '看到', '要说', '诺说', '商定', '做客', '想到', '正视', '争议', '对待', '用词', '看好', '托说', '之所以', '为什么', '邵杰', '留意', '访俄', '可行性', '更何况', '回避', '低估', '提出', '商榷', '马平摄', '看球', '森说', '因为', '感兴趣', '可能', '常说', '担忧', '归功于', '慎重', '回想', '确实', '不过', '不明智', '态度', '依赖', '因循守旧', '认可', '南方日报', '警惕', '翟健岚摄', '商讨', '实际上', '显然', '刁', '经济委员会', '并不认为', '关于', '可信度', '撼动', 'FOMC', '与会', '根据', '赞赏', '把脉', '忽略', '中国社科院', '手记', '阐述', '施政', '归因于', '人心所向', '看重', '争论', '忽视', '谈及', '智囊团', '他称', '考量', '有何', '寄望', '保守', '讨论', '也许', '导报', '网络安全', '或许', '认知', '放言', '当然', '一方面', '围绕', '寄希望于', '看待', '基于', '促使', '表明', '认清', '或者说', '信心', '由此可见', '预算', '银行业', '因此', '尽管', '冯俊伟', '远不如', '积极', '依赖于', '关系', '高度重视', '主张', '可能性', '确信', '宏观', '审慎', '意料之中', '的确', '削弱', '权威', '时说', '可控', '普遍', '其次', '预计', '两党', '来说', '政治', '归咎于', '毕竟', '处境', '智库', '国际货币基金组织', '孤立', '肯定', '电影界', '而言', '经济运行', '企业界', '分歧', '当前', '充满信心', '威慑', '金融监管', '来讲', '另一方面', '货币政策', '金融业', '事实上', '发挥作用', '视为', '这方面', '期望', '轮值', '首先', '坚信', '明确提出', '对亚', '军事', '重视', '积极参与', '策略', '基建投资', '现状', '前景', '调门', '众所周知', '主导权', '进程', '访', '相信', '设想', '现阶段', '外交政策', '普遍认为', '预测', '预料', '有所作为', '谈到']\n"
     ]
    }
   ],
   "source": [
    "print([''.join(n) for n in related_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:40: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    }
   ],
   "source": [
    "related_words_250 = get_related_words(['说','表示','认为','建议'], \n",
    "                                      news_word2vec, max_size=250, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(related_words_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['指出', '透露', '所说', '说', '称', '认为', '表示', '告诉', '承认', '声称', '时说', '说道', '文说', '坦言', '普遍认为', '直言', '强调', '中说', '说法', '提及', '批评', '提到', '看来', '看法', '写道', '中称', '明说', '对此', '如是说', '推测', '观点', '提醒', '呼吁', '抨击', '介绍', '暗示', '猜测', '表态', '质疑', '纳说', '地说', '深有体会', '回答', '因斯', '称赞', '坦承', '留意到', '敦促', '解释', '建议', '提议', '置评', '谈到', '问', '宣称', '重申', '评述', '事实上', '对瓦姆', '预言', '主张', '中国外交部', '申明', '怀疑', '相信', '特别强调', '预料', '感叹', '觉得', '疑虑', '估计', '所指', '担心', '并不知道', '显然', '佩服', '援引', '分析', '引述', '评价', '却说', '认同', '问过', '看好', '深表', '否认', '还称', '理解', '眼中', '镐', '感慨', '宣布', '另据', '强调指出', '追究责任', '问道', '预测', '谈论', '但据', '鲁金博', '发问', '周效政', '反复强调', '邵杰', '解读', '告诫', '谈及', '华商报', '得知', '每经', '意料之中', '深知', '要求', '询问', '董', '古稀之年', '奉劝', '形容', '听说', '问起', '徐海', '夸赞', '自称', '红霞', '要说', '回复', '注意', '侃侃而谈', '的话', '并称', '反问', '庆幸', '谨慎', '暂且', '冯俊伟摄', '聊起', '说起', '发给', '祁', '圈子里', '对策', '北青报', '国利', '慎重', '地问', '考虑', '其实', '的确', '翃', '李骥志摄', '采纳', '力推', '锦', '不难看出', '振声', '张隽玮', '海涛', '艳红', '明确指出', '常说', '劝', '这令', '南方日报', '在我看来', '更何况', '一峰', '眼里', '众所周知', '一方面', '李佳', '合理性', '说错', '叮嘱', '请', '提', '明哲', '应该', '热罗姆', '回访', '同意', '看出', '洪说', '决定', '纷纷表示', '说真的', '张玉洁', '见到', '首先', '必要', '解答', '志峰', '桂平', '提示', '这方面', '想必', '看到', '应', '伟民', '而言', '谈起', '面前', '确实', '鹏飞', '提出', '专家建议', '毕竟', '需谨慎', '春晖', '德昌', '永年', '策略', '参考', '务必', '冬冬', '亲眼看到', '来说', '志强', '来讲', '立新', '某林', '保国', '徐国', '剧里', '补充', '洪涛', '志军', '常务', '指南', '化验员', '青峰', '农艺师', '明确提出', '选择', '爱华', '刘', '道', '及其', '意见', '推荐', '武说', '适当', '要点', '相应', '方案', '合理', '鼓励', '河村', '主动', '永康', '尽量']\n"
     ]
    }
   ],
   "source": [
    "print(related_words_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out stop words\n",
    "\n",
    "file_path = './chinese_stopwords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = []\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        stop_list.append(line[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "\n",
    "for w in related_words_250:\n",
    "    if w not in stop_list:\n",
    "        words_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter out the non-verbs using the `pos` tags. Both `jieba` and `stanfordcorenlp` provide such features. Here we use `corenlp`. \n",
    "\n",
    "To launch the nlp server with the chinese model jar, run the following in the `corenlp` folder in terminal:\n",
    "\n",
    "```bash\n",
    "java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -serverProperties StanfordCoreNLP-chinese.properties -port 9090 -timeout 15000 --add-modules java.se.ee\n",
    "```\n",
    "note that the port was changed to 9090 (the default for corenlp is 9000), since 9000 is already in use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ch = nlp.annotate(words,\n",
    "                   properties={\n",
    "                       'annotators': 'tokenize,ssplit,pos',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 10000,\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'指出 (VV) 透露 (VV) 所说 (NN) 认为 (VV) 表示 (VV) 告诉 (VV) 承认 (VV) 声称 (VV) 时 (LC) 说 (VV) 说道 (VV) 文说 (AD) 坦言 (VV) 普遍 (AD) 认为 (VV) 直言 (VV) 强调 (VV) 中 (LC) 说 (VV) 说法 (NN) 提及 (VV) 批评 (NN) 提到 (VV) 看来 (VV) 看法 (NN) 写道 (VV) 中 (LC) 称 (VV) 明说 (VV) 对此 (AD) 如是 (AD) 说 (VV) 推测 (VV) 观点 (NN) 提醒 (VV) 呼吁 (VV) 抨击 (NN) 介绍 (VV) 暗示 (VV) 猜测 (VV) 表态 (NN) 质疑 (NN) 纳 (NR) 说 (VV) 地 (DEV) 说 (VV) 深有 (VV) 体会 (NN) 回答 (VV) 因 (P) 斯 (NR) 称赞 (VV) 坦承 (VV) 留意 (VV) 到 (VV) 敦促 (VV) 解释 (VV) 建议 (VV) 提议 (VV) 置评 (AD) 谈到 (VV) 问 (VV) 宣称 (VV) 重申 (VV) 评述 (NN) 事实上 (AD) 对 (P) 瓦姆 (NR) 预言 (NN) 主张 (VV) 中国 (NR) 外交部 (NN) 申明 (VV) 怀疑 (NN) 相信 (VV) 特别 (AD) 强调 (VV) 预料 (NN) 感叹 (NN) 觉得 (VV) 疑虑 (NN) 估计 (VV) 所指 (NN) 担心 (VV) 并不 (AD) 知道 (VV) 显然 (AD) 佩服 (VV) 援引 (VV) 分析 (NN) 引述 (VV) 评价 (NN) 却 (AD) 说 (VV) 认同 (VV) 问 (VV) 过 (AS) 看好 (VV) 深表 (VV) 否认 (VV) 还 (AD) 称 (VV) 理解 (VV) 眼 (NN) 中 (LC) 镐 (M) 感慨 (NN) 宣布 (VV) 另据 (NR) 强调 (VV) 指出 (VV) 追究 (VV) 责任 (NN) 问道 (VV) 预测 (VV) 谈论 (VV) 但 (AD) 据 (P) 鲁 (NR) 金博 (NR) 发问 (VV) 周效政 (NR) 反复 (AD) 强调 (VV) 邵杰 (NR) 解读 (VV) 告诫 (VV) 谈及 (VV) 华商 (NN) 报 (VV) 得知 (VV) 每 (DT) 经 (P) 意料 (NN) 之中 (LC) 深知 (VV) 要求 (VV) 询问 (VV) 董 (NR) 古稀 (NN) 之 (DEG) 年 (NN) 奉劝 (VV) 形容 (VV) 听说 (VV) 问起 (VV) 徐海 (NR) 夸赞 (VV) 自称 (VV) 红霞 (AD) 要 (VV) 说 (VV) 回复 (VV) 注意 (VV) 侃侃而谈 (VV) 的话 (SP) 并称 (VV) 反问 (JJ) 庆幸 (NN) 谨慎 (AD) 暂且 (AD) 冯俊伟 (NR) 摄 (VV) 聊起 (VV) 说起 (VV) 发给 (VV) 祁 (NR) 圈子 (NN) 里 (LC) 对策 (NN) 北青 (NN) 报 (VV) 国 (NN) 利 (NN) 慎重 (VA) 地 (DEV) 问 (VV) 考虑 (VV) 其实 (AD) 的确 (AD) 翃 (VV) 李骥志 (NR) 摄 (VV) 采纳 (VV) 力推 (VV) 锦 (NN) 不 (AD) 难 (AD) 看出 (VV) 振声 (NN) 张隽玮 (NR) 海涛 (NN) 艳红 (NN) 明确 (AD) 指出 (VV) 常 (AD) 说 (VV) 劝 (VV) 这 (DT) 令 (VV) 南方 (NN) 日报 (NN) 在 (P) 我 (PN) 看来 (LC) 更 (AD) 何况 (AD) 一 (CD) 峰 (NN) 眼 (NN) 里 (LC) 众所周知 (VV) 一方面 (AD) 李佳 (NR) 合理性 (NN) 说错 (VV) 叮嘱 (NN) 请 (VV) 提 (VV) 明哲 (NN) 应该 (VV) 热 (JJ) 罗姆 (NR) 回访 (VV) 同意 (VV) 看出 (VV) 洪 (NR) 说 (VV) 决定 (VV) 纷纷 (AD) 表示 (VV) 说真的 (VV) 张玉洁 (NR) 见到 (VV) 首先 (AD) 必要 (JJ) 解答 (VV) 志 (NN) 峰 (NN) 桂平 (NR) 提示 (VV) 这 (DT) 方面 (NN) 想必 (AD) 看到 (VV) 应 (VV) 伟民 (VV) 而 (MSP) 言 (VV) 谈起 (VV) 面前 (NN) 确实 (AD) 鹏飞 (VV) 提出 (VV) 专家 (NN) 建议 (NN) 毕竟 (AD) 需 (VV) 谨慎 (VA) 春晖 (NR) 德昌 (NR) 永年 (AD) 策略 (NN) 参考 (NN) 务必 (AD) 冬冬 (VV) 亲眼 (AD) 看到 (VV) 来说 (LC) 志强 (AD) 来讲 (LC) 立新 (NN) 某 (DT) 林 (NN) 保国 (NN) 徐国 (NR) 剧里 (NN) 补充 (VV) 洪涛 (NN) 志军 (NN) 常务 (JJ) 指南 (NN) 化验员 (NN) 青峰 (NN) 农艺师 (NN) 明确 (AD) 提出 (VV) 选择 (NN) 爱 (VV) 华 (NR) 刘 (NR) 道 (NN) 及 (CC) 其 (PN) 意见 (NN) 推荐 (VV) 武说 (VV) 适当 (JJ) 要点 (NN) 相应 (JJ) 方案 (NN) 合理 (AD) 鼓励 (VV) 河 (NN) 村 (NN) 主动 (AD) 永康 (NR) 尽量 (AD)'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the pos tags\n",
    "pos = []\n",
    "\n",
    "for token in result_ch[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(token['word'], token['pos']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "saying_verbs = []\n",
    "\n",
    "for token in result_ch[\"sentences\"][0]['tokens']:\n",
    "    if token['pos'] == 'VV':\n",
    "        saying_verbs.append(token['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['指出', '透露', '认为', '表示', '告诉', '承认', '声称', '说', '说道', '坦言', '认为', '直言', '强调', '说', '提及', '提到', '看来', '写道', '称', '明说', '说', '推测', '提醒', '呼吁', '介绍', '暗示', '猜测', '说', '说', '深有', '回答', '称赞', '坦承', '留意', '到', '敦促', '解释', '建议', '提议', '谈到', '问', '宣称', '重申', '主张', '申明', '相信', '强调', '觉得', '估计', '担心', '知道', '佩服', '援引', '引述', '说', '认同', '问', '看好', '深表', '否认', '称', '理解', '宣布', '强调', '指出', '追究', '问道', '预测', '谈论', '发问', '强调', '解读', '告诫', '谈及', '报', '得知', '深知', '要求', '询问', '奉劝', '形容', '听说', '问起', '夸赞', '自称', '要', '说', '回复', '注意', '侃侃而谈', '并称', '摄', '聊起', '说起', '发给', '报', '问', '考虑', '翃', '摄', '采纳', '力推', '看出', '指出', '说', '劝', '令', '众所周知', '说错', '请', '提', '应该', '回访', '同意', '看出', '说', '决定', '表示', '说真的', '见到', '解答', '提示', '看到', '应', '伟民', '言', '谈起', '鹏飞', '提出', '需', '冬冬', '看到', '补充', '提出', '爱', '推荐', '武说', '鼓励']\n"
     ]
    }
   ],
   "source": [
    "print(saying_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also filter out duplicates\n",
    "\n",
    "len(set(saying_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'深表', '解释', '谈及', '鼓励', '要', '说道', '得知', '呼吁', '要求', '采纳', '自称', '深知', '宣布', '认为', '写道', '看出', '敦促', '坦承', '预测', '谈论', '问起', '武说', '承认', '推测', '伟民', '相信', '问', '理解', '说起', '称赞', '众所周知', '考虑', '看好', '询问', '提示', '暗示', '深有', '到', '提及', '否认', '指出', '强调', '见到', '夸赞', '提出', '翃', '直言', '担心', '发给', '奉劝', '回访', '宣称', '佩服', '应该', '决定', '称', '同意', '告诉', '声称', '提议', '请', '谈起', '回复', '看来', '补充', '注意', '看到', '提', '应', '重申', '摄', '留意', '告诫', '回答', '明说', '主张', '令', '说真的', '听说', '需', '说错', '认同', '猜测', '爱', '鹏飞', '并称', '言', '形容', '谈到', '力推', '提醒', '解读', '追究', '聊起', '建议', '报', '劝', '透露', '援引', '问道', '坦言', '推荐', '侃侃而谈', '知道', '提到', '引述', '表示', '觉得', '冬冬', '估计', '介绍', '说', '发问', '解答', '申明'}\n"
     ]
    }
   ],
   "source": [
    "print(set(saying_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saying_verbs.txt', 'w') as f:\n",
    "    for n in set(saying_verbs):\n",
    "        f.write(str(n) + '\\n')\n",
    "        \n",
    "# now we can mannually delete irrelevant words in the .txt file :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
