{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 05 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Implement a Word2Vec Model using the News Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a Word2Vec model\n",
    "\n",
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "# Paramters for 'Word2Vec' in the gensim package:\n",
    "# -- sentences (iterable of list of str): Can be simply a list of lists of tokens, but for larger corpora, \n",
    "#     consider an iterable that streams the sentences directly from disk/network. \n",
    "#     See BrownCorpus, Text8Corpus or LineSentence module for such examples.\n",
    "# -- min_count: Words below the min_count frequency are dropped before training occurs.\n",
    "#     The default value is min_count = 5\n",
    "#\n",
    "# See documentation here: \n",
    "# https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.LineSentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': <gensim.models.keyedvectors.Vocab at 0x12b904940>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x12b904048>,\n",
       " 'meow': <gensim.models.keyedvectors.Vocab at 0x12b904f98>,\n",
       " 'dog': <gensim.models.keyedvectors.Vocab at 0x12b9044e0>,\n",
       " 'woof': <gensim.models.keyedvectors.Vocab at 0x12b904ef0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('say', 0.07369384914636612),\n",
       " ('woof', 0.0512646846473217),\n",
       " ('dog', 0.043911129236221313),\n",
       " ('meow', -0.04825589805841446)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cat') # check out the most similar words for \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.5524435e-03,  4.3167290e-03, -1.9331600e-03,  1.4156078e-03,\n",
       "        1.5240088e-03, -4.6887097e-04, -1.8123303e-03, -3.1281598e-03,\n",
       "       -1.0598174e-03, -4.6913023e-03,  4.3256516e-03, -2.4396495e-03,\n",
       "       -3.2000607e-03,  3.3786276e-03,  4.4470131e-03, -4.1932724e-03,\n",
       "        2.5538651e-03, -4.8114667e-03,  4.8077307e-03,  1.0756694e-03,\n",
       "       -2.8313601e-03,  3.3936216e-04, -1.3326895e-03,  2.1480329e-03,\n",
       "       -1.0317875e-03,  1.0735678e-03, -5.8563414e-04, -3.6414443e-03,\n",
       "        2.5576167e-04,  2.3993750e-03,  3.0371237e-03,  2.0543532e-03,\n",
       "       -3.7211739e-03,  4.5596221e-03,  4.7293343e-03,  1.1081680e-03,\n",
       "       -4.0781870e-03, -2.8813148e-03, -3.4635402e-03, -7.3132112e-05,\n",
       "        1.6330541e-03, -3.6698077e-03,  3.6049262e-03, -2.3594000e-03,\n",
       "       -3.0682206e-03,  7.7385473e-04,  8.4273046e-04, -3.7035465e-03,\n",
       "       -1.3521563e-03,  8.6767157e-04,  4.4918987e-03,  4.1219322e-03,\n",
       "       -4.8194081e-03,  4.8602805e-03,  2.3068113e-03, -4.4915131e-03,\n",
       "        7.4600358e-04,  4.7343229e-03,  1.6873421e-03,  1.2335327e-03,\n",
       "        6.0393388e-04, -1.3112735e-03,  3.2410489e-03,  4.7766943e-03,\n",
       "        7.8081625e-04,  1.5041351e-03, -3.2336304e-03,  4.8895011e-04,\n",
       "       -2.4409774e-03, -3.2388398e-03,  4.2553698e-03, -4.3361322e-03,\n",
       "       -3.8299744e-03,  8.9038786e-04, -2.0657196e-04,  6.8293430e-04,\n",
       "        1.3084119e-03, -2.3236575e-03,  1.2444654e-03,  1.0166868e-03,\n",
       "       -1.6806225e-03, -3.1870946e-03,  2.0517234e-03, -2.6165328e-03,\n",
       "        4.4956803e-03,  9.1992354e-04, -4.4405097e-03, -2.8516115e-03,\n",
       "        4.7013029e-03,  4.5237471e-03, -3.3897955e-03,  8.9929893e-04,\n",
       "        4.1484851e-03, -4.3824674e-03, -2.3207822e-04, -3.8886315e-03,\n",
       "        5.1164383e-04, -3.7538379e-03,  3.1339925e-05,  3.5285235e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['dog'] # check out the word vector for 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try word2vec using a larger corpus (the chinese news corpus in LineSentence format)\n",
    "\n",
    "line_setences_path = '/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/sentences-cut.txt'\n",
    "sentences = LineSentence(line_setences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_model = Word2Vec(sentences, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46606752,  0.0603839 ,  0.12178345, -0.6077574 ,  0.35224456,\n",
       "        0.1260093 ,  0.2057447 ,  0.02758181,  0.7849377 ,  0.25842643,\n",
       "       -0.11409037,  0.64268595,  0.17382361,  0.91700697,  2.6077218 ,\n",
       "        0.29584727, -1.1201617 , -0.34778276,  0.18813357, -0.23707744,\n",
       "       -0.2701578 , -1.8964182 , -1.1023777 , -0.38531917, -0.94263166,\n",
       "       -0.5404368 , -0.1292999 ,  0.94657075, -0.5578564 ,  1.5042089 ,\n",
       "       -1.087818  ,  1.1199632 ,  1.6911533 ,  0.45593718,  0.574618  ,\n",
       "       -0.33724988,  0.12162794, -0.6187379 , -0.09358543,  0.28237635,\n",
       "        0.64235187, -0.09404029,  0.11260442, -0.3531185 ,  0.07025079,\n",
       "       -0.07933626,  0.4417101 , -0.14876136,  0.57109916,  2.2883537 ,\n",
       "       -1.1443634 , -1.4978299 ,  0.58583254, -1.0405807 , -0.86536634,\n",
       "        1.2698337 , -1.6695113 , -1.0639921 , -0.10368778, -0.7882075 ,\n",
       "       -0.49955893,  0.02908174, -0.00261209, -1.4894137 , -0.28617343,\n",
       "       -0.19373026,  0.18372041, -1.2616925 , -0.64112276, -0.13040423,\n",
       "        0.3419577 , -0.11636168,  0.5480165 , -0.20171285, -0.2016951 ,\n",
       "       -0.4376533 ,  0.9228487 , -1.8016642 ,  0.753662  ,  0.97697514,\n",
       "       -0.23407589,  0.16724002,  0.6820113 ,  0.21911979,  0.9068146 ,\n",
       "        1.4623288 ,  0.01977767, -0.16164243,  0.52870303,  0.2715356 ,\n",
       "        0.8977084 ,  0.84277564, -0.6707817 , -0.12569709, -0.0691172 ,\n",
       "       -0.9038181 , -0.29779035, -1.0893905 , -0.6779775 , -0.37280732],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.wv['小米']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('OPPO', 0.7341985106468201),\n",
       " ('华为', 0.7296118140220642),\n",
       " ('苹果', 0.7029392719268799),\n",
       " ('生鲜', 0.700323224067688),\n",
       " ('三星', 0.6948364973068237),\n",
       " ('S8', 0.6868998408317566),\n",
       " ('格力', 0.685062050819397),\n",
       " ('家电', 0.6844112277030945),\n",
       " ('亚马逊', 0.6718410849571228),\n",
       " ('智能手机', 0.6623239517211914)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.most_similar('小米')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('三星', 0.8230892419815063),\n",
       " ('西门子', 0.7642229795455933),\n",
       " ('中兴', 0.7625566720962524),\n",
       " ('OPPO', 0.7476036548614502),\n",
       " ('谷歌', 0.7430927753448486),\n",
       " ('阿里巴巴', 0.7340729236602783),\n",
       " ('上汽', 0.7331277132034302),\n",
       " ('蚂蚁', 0.7311336994171143),\n",
       " ('小米', 0.7296118140220642),\n",
       " ('英特尔', 0.7259373664855957)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.most_similar('华为')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('沃尔玛', 0.776244044303894),\n",
       " ('京东', 0.7541892528533936),\n",
       " ('谷歌', 0.7526918649673462),\n",
       " ('苹果公司', 0.718194842338562),\n",
       " ('微软', 0.7116185426712036),\n",
       " ('零售商', 0.7107131481170654),\n",
       " ('苹果', 0.7026939392089844),\n",
       " ('天猫', 0.7006959915161133),\n",
       " ('阿里巴巴', 0.696462869644165),\n",
       " ('Google', 0.691777229309082)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model.most_similar('亚马逊')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's save the word vectors to a local directory for future use!\n",
    "\n",
    "# first, we can save the model\n",
    "news_model.save('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/news_model')\n",
    "\n",
    "# to load a model, use the following:\n",
    "# news_model = gensim.models.Word2Vec.load('news_model')\n",
    "\n",
    "# Advanced users can load a model and continue training it with more sentences:\n",
    "#model = gensim.models.Word2Vec.load('path/to/mymodel')\n",
    "#model.train(more_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, we can also save the word vectors for future query\n",
    "filename = '/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/news_model_word_vectors.kv'\n",
    "word_vectors = news_model.wv\n",
    "word_vectors.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as binary format (.bin)\n",
    "word_vectors.save_word2vec_format('/Users/xinweixu/Dropbox/learn/Comp_Prog/nlp/data/news_model_word_vectors.bin', binary=True)\n",
    "\n",
    "# or as .txt\n",
    "# word_vectors.save_word2vec_format('path/to/<file_name>.txt', binary=False)\n",
    "# note that .bin takes less space than .txt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load word vectors from a local directory, use the following:\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "# filename = get_tmpfile('<file_path>')\n",
    "# word_vectors = KeyedVectors.load(filename, mmap='r')\n",
    "\n",
    "# or we can also load binary word vectors into a model:\n",
    "#model = KeyedVectors.load_word2vec_format('path/to/<file_name>.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For more info on storing and querying word vectors, see: https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Name Entity Recognition & Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using jieba.posseg\n",
    "posseg = part of speech segment，\n",
    "`jieba.posseg` 标注句子分词后每个词的词性，采用ictclas兼容的标记法。对于词性注释，见表格：https://blog.csdn.net/suibianshen2012/article/details/53487157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"新华社华盛顿4月26日电 美国总统特朗普26日表示，美国将撤销在《武器贸易条约》上的签字。\n",
    "\n",
    "特朗普当天在美国印第安纳州首府印第安纳波利斯举行的美国全国步枪协会年会上说，《武器贸易条约》是一个“严重误导的条约”，美国将撤销在该条约上的签字，联合国将很快收到美国正式拒绝该条约的通知。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pseg.cut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/1y/1btp7xpj7b1f82lnwvn2916h0000gn/T/jieba.cache\n",
      "Loading model cost 0.683 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新华社 nt\n",
      "华盛顿 ns\n",
      "4 m\n",
      "月 m\n",
      "26 m\n",
      "日电 j\n",
      "  x\n",
      "美国 ns\n",
      "总统 n\n",
      "特朗普 nr\n",
      "26 m\n",
      "日 m\n",
      "表示 v\n",
      "， x\n",
      "美国 ns\n",
      "将 d\n",
      "撤销 v\n",
      "在 p\n",
      "《 x\n",
      "武器 n\n",
      "贸易 vn\n",
      "条约 n\n",
      "》 x\n",
      "上 f\n",
      "的 uj\n",
      "签字 v\n",
      "。 x\n",
      "\n",
      " x\n",
      "\n",
      " x\n",
      "特朗普 nr\n",
      "当天 t\n",
      "在 p\n",
      "美国 ns\n",
      "印第安纳州 ns\n",
      "首府 n\n",
      "印第安纳波利斯 ns\n",
      "举行 v\n",
      "的 uj\n",
      "美国 ns\n",
      "全国 n\n",
      "步枪 n\n",
      "协会 n\n",
      "年 m\n",
      "会上 t\n",
      "说 v\n",
      "， x\n",
      "《 x\n",
      "武器 n\n",
      "贸易 vn\n",
      "条约 n\n",
      "》 x\n",
      "是 v\n",
      "一个 m\n",
      "“ x\n",
      "严重 a\n",
      "误导 n\n",
      "的 uj\n",
      "条约 n\n",
      "” x\n",
      "， x\n",
      "美国 ns\n",
      "将 d\n",
      "撤销 v\n",
      "在 p\n",
      "该 r\n",
      "条约 n\n",
      "上 f\n",
      "的 uj\n",
      "签字 v\n",
      "， x\n",
      "联合国 nt\n",
      "将 d\n",
      "很快 d\n",
      "收到 v\n",
      "美国 ns\n",
      "正式 ad\n",
      "拒绝 v\n",
      "该 r\n",
      "条约 n\n",
      "的 uj\n",
      "通知 v\n",
      "。 x\n"
     ]
    }
   ],
   "source": [
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using pyltp (by HIT)\n",
    "pyltp 是语言技术平台 （language technology platform）的python 封装。 \n",
    "\n",
    "github page: https://github.com/HIT-SCIR/pyltp\n",
    "\n",
    "documentation: https://pyltp.readthedocs.io/zh_CN/latest/api.html#id13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5d03b641ee58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyltp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPostagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "from pyltp import Postagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyltp install failed on macOS 10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. stanford-corenlp\n",
    "\n",
    "For a list of python packages using the Stanford-CoreNLP server:\n",
    "https://stanfordnlp.github.io/CoreNLP/other-languages.html\n",
    "\n",
    "Here we use `pycorenlp` for its simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the python interface, we need to launch the CoreNLP server from the terminal:\n",
    "```bash\n",
    "cd path/to/CoreNLP/folder\n",
    "java -mx6g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 5000 --add-modules java.se.ee\n",
    "```\n",
    "The parameter `-mx6g` specifies the amount of memory that CoreNLP is allowed to use. In this case, it’s six gigabytes. The `-timeout 5000` parameter specifies the timeout in milliseconds. `--add-modules java.se.ee` is for java version 9/10/11.\n",
    "\n",
    "\n",
    "\n",
    "See more info: \n",
    "https://towardsdatascience.com/natural-language-processing-using-stanfords-corenlp-d9e64c1e1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This movie was actually neither that funny, nor super witty. I liked watching that movie. If I had a choice, I would not watch that movie again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nlp.annotate(text,\n",
    "                   properties={\n",
    "                       'annotators': 'ner, pos',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                   })\n",
    "\n",
    "# possible annotators:\n",
    "# annotators: tokenize, ssplit, pos, lemma, ner, parse, dcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'entitymentions': [],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'This',\n",
       "    'originalText': 'This',\n",
       "    'lemma': 'this',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 4,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'movie',\n",
       "    'originalText': 'movie',\n",
       "    'lemma': 'movie',\n",
       "    'characterOffsetBegin': 5,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 3,\n",
       "    'word': 'was',\n",
       "    'originalText': 'was',\n",
       "    'lemma': 'be',\n",
       "    'characterOffsetBegin': 11,\n",
       "    'characterOffsetEnd': 14,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'actually',\n",
       "    'originalText': 'actually',\n",
       "    'lemma': 'actually',\n",
       "    'characterOffsetBegin': 15,\n",
       "    'characterOffsetEnd': 23,\n",
       "    'pos': 'RB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 5,\n",
       "    'word': 'neither',\n",
       "    'originalText': 'neither',\n",
       "    'lemma': 'neither',\n",
       "    'characterOffsetBegin': 24,\n",
       "    'characterOffsetEnd': 31,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 6,\n",
       "    'word': 'that',\n",
       "    'originalText': 'that',\n",
       "    'lemma': 'that',\n",
       "    'characterOffsetBegin': 32,\n",
       "    'characterOffsetEnd': 36,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 7,\n",
       "    'word': 'funny',\n",
       "    'originalText': 'funny',\n",
       "    'lemma': 'funny',\n",
       "    'characterOffsetBegin': 37,\n",
       "    'characterOffsetEnd': 42,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 8,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 42,\n",
       "    'characterOffsetEnd': 43,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 9,\n",
       "    'word': 'nor',\n",
       "    'originalText': 'nor',\n",
       "    'lemma': 'nor',\n",
       "    'characterOffsetBegin': 44,\n",
       "    'characterOffsetEnd': 47,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 10,\n",
       "    'word': 'super',\n",
       "    'originalText': 'super',\n",
       "    'lemma': 'super',\n",
       "    'characterOffsetBegin': 48,\n",
       "    'characterOffsetEnd': 53,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 11,\n",
       "    'word': 'witty',\n",
       "    'originalText': 'witty',\n",
       "    'lemma': 'witty',\n",
       "    'characterOffsetBegin': 54,\n",
       "    'characterOffsetEnd': 59,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 12,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 59,\n",
       "    'characterOffsetEnd': 60,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '}]},\n",
       " {'index': 1,\n",
       "  'entitymentions': [],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'I',\n",
       "    'originalText': 'I',\n",
       "    'lemma': 'I',\n",
       "    'characterOffsetBegin': 61,\n",
       "    'characterOffsetEnd': 62,\n",
       "    'pos': 'PRP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'liked',\n",
       "    'originalText': 'liked',\n",
       "    'lemma': 'like',\n",
       "    'characterOffsetBegin': 63,\n",
       "    'characterOffsetEnd': 68,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 3,\n",
       "    'word': 'watching',\n",
       "    'originalText': 'watching',\n",
       "    'lemma': 'watch',\n",
       "    'characterOffsetBegin': 69,\n",
       "    'characterOffsetEnd': 77,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'that',\n",
       "    'originalText': 'that',\n",
       "    'lemma': 'that',\n",
       "    'characterOffsetBegin': 78,\n",
       "    'characterOffsetEnd': 82,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 5,\n",
       "    'word': 'movie',\n",
       "    'originalText': 'movie',\n",
       "    'lemma': 'movie',\n",
       "    'characterOffsetBegin': 83,\n",
       "    'characterOffsetEnd': 88,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 6,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 88,\n",
       "    'characterOffsetEnd': 89,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '}]},\n",
       " {'index': 2,\n",
       "  'entitymentions': [],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'If',\n",
       "    'originalText': 'If',\n",
       "    'lemma': 'if',\n",
       "    'characterOffsetBegin': 90,\n",
       "    'characterOffsetEnd': 92,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'I',\n",
       "    'originalText': 'I',\n",
       "    'lemma': 'I',\n",
       "    'characterOffsetBegin': 93,\n",
       "    'characterOffsetEnd': 94,\n",
       "    'pos': 'PRP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 3,\n",
       "    'word': 'had',\n",
       "    'originalText': 'had',\n",
       "    'lemma': 'have',\n",
       "    'characterOffsetBegin': 95,\n",
       "    'characterOffsetEnd': 98,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'a',\n",
       "    'originalText': 'a',\n",
       "    'lemma': 'a',\n",
       "    'characterOffsetBegin': 99,\n",
       "    'characterOffsetEnd': 100,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 5,\n",
       "    'word': 'choice',\n",
       "    'originalText': 'choice',\n",
       "    'lemma': 'choice',\n",
       "    'characterOffsetBegin': 101,\n",
       "    'characterOffsetEnd': 107,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 6,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 107,\n",
       "    'characterOffsetEnd': 108,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 7,\n",
       "    'word': 'I',\n",
       "    'originalText': 'I',\n",
       "    'lemma': 'I',\n",
       "    'characterOffsetBegin': 109,\n",
       "    'characterOffsetEnd': 110,\n",
       "    'pos': 'PRP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 8,\n",
       "    'word': 'would',\n",
       "    'originalText': 'would',\n",
       "    'lemma': 'would',\n",
       "    'characterOffsetBegin': 111,\n",
       "    'characterOffsetEnd': 116,\n",
       "    'pos': 'MD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 9,\n",
       "    'word': 'not',\n",
       "    'originalText': 'not',\n",
       "    'lemma': 'not',\n",
       "    'characterOffsetBegin': 117,\n",
       "    'characterOffsetEnd': 120,\n",
       "    'pos': 'RB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 10,\n",
       "    'word': 'watch',\n",
       "    'originalText': 'watch',\n",
       "    'lemma': 'watch',\n",
       "    'characterOffsetBegin': 121,\n",
       "    'characterOffsetEnd': 126,\n",
       "    'pos': 'VB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 11,\n",
       "    'word': 'that',\n",
       "    'originalText': 'that',\n",
       "    'lemma': 'that',\n",
       "    'characterOffsetBegin': 127,\n",
       "    'characterOffsetEnd': 131,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 12,\n",
       "    'word': 'movie',\n",
       "    'originalText': 'movie',\n",
       "    'lemma': 'movie',\n",
       "    'characterOffsetBegin': 132,\n",
       "    'characterOffsetEnd': 137,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 13,\n",
       "    'word': 'again',\n",
       "    'originalText': 'again',\n",
       "    'lemma': 'again',\n",
       "    'characterOffsetBegin': 138,\n",
       "    'characterOffsetEnd': 143,\n",
       "    'pos': 'RB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 14,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 143,\n",
       "    'characterOffsetEnd': 144,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ''}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This (O) movie (O) was (O) actually (O) neither (O) that (O) funny (O) , (O) nor (O) super (O) witty (O) . (O)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the labels from NER (name recognition entity)\n",
    "\n",
    "pos = []\n",
    "for word in result[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['ner']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this example, all the NER labels seem to be o,\n",
    "# try another example -- a random news excerpt from Financial Times:\n",
    "\n",
    "text2 = \"Europe and the US have warned Iran against reviving its nuclear programme after Tehran said it would stop complying with parts of a 2015 atomic deal, raising the stakes in the regime’s stand-off with the Trump administration.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = nlp.annotate(text2,\n",
    "                   properties={\n",
    "                       'annotators': 'ner, pos',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                   })\n",
    "\n",
    "\n",
    "# using the 'sentiment' annotator gives error!\n",
    "# related issue reported here:\n",
    "# https://github.com/stanfordnlp/CoreNLP/issues/347\n",
    "# but not able to solve the error after adding ejml.jar to the classpath..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'entitymentions': [{'docTokenBegin': 0,\n",
       "    'docTokenEnd': 1,\n",
       "    'tokenBegin': 0,\n",
       "    'tokenEnd': 1,\n",
       "    'text': 'Europe',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 6,\n",
       "    'ner': 'LOCATION',\n",
       "    'nerConfidences': {'LOCATION': 0.93099511643904}},\n",
       "   {'docTokenBegin': 3,\n",
       "    'docTokenEnd': 4,\n",
       "    'tokenBegin': 3,\n",
       "    'tokenEnd': 4,\n",
       "    'text': 'US',\n",
       "    'characterOffsetBegin': 15,\n",
       "    'characterOffsetEnd': 17,\n",
       "    'ner': 'COUNTRY',\n",
       "    'nerConfidences': {'LOCATION': 0.99806632305234}},\n",
       "   {'docTokenBegin': 6,\n",
       "    'docTokenEnd': 7,\n",
       "    'tokenBegin': 6,\n",
       "    'tokenEnd': 7,\n",
       "    'text': 'Iran',\n",
       "    'characterOffsetBegin': 30,\n",
       "    'characterOffsetEnd': 34,\n",
       "    'ner': 'COUNTRY',\n",
       "    'nerConfidences': {'LOCATION': 0.99568029031225}},\n",
       "   {'docTokenBegin': 13,\n",
       "    'docTokenEnd': 14,\n",
       "    'tokenBegin': 13,\n",
       "    'tokenEnd': 14,\n",
       "    'text': 'Tehran',\n",
       "    'characterOffsetBegin': 80,\n",
       "    'characterOffsetEnd': 86,\n",
       "    'ner': 'LOCATION',\n",
       "    'nerConfidences': {'LOCATION': 0.92346755123946}},\n",
       "   {'docTokenBegin': 23,\n",
       "    'docTokenEnd': 24,\n",
       "    'tokenBegin': 23,\n",
       "    'tokenEnd': 24,\n",
       "    'text': '2015',\n",
       "    'characterOffsetBegin': 132,\n",
       "    'characterOffsetEnd': 136,\n",
       "    'ner': 'DATE',\n",
       "    'normalizedNER': '2015',\n",
       "    'nerConfidences': {'DATE': 0.88390358598478}},\n",
       "   {'docTokenBegin': 37,\n",
       "    'docTokenEnd': 38,\n",
       "    'tokenBegin': 37,\n",
       "    'tokenEnd': 38,\n",
       "    'text': 'Trump',\n",
       "    'characterOffsetBegin': 204,\n",
       "    'characterOffsetEnd': 209,\n",
       "    'ner': 'PERSON',\n",
       "    'nerConfidences': {'PERSON': 0.9011943446962}}],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'Europe',\n",
       "    'originalText': 'Europe',\n",
       "    'lemma': 'Europe',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 6,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'LOCATION',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'and',\n",
       "    'originalText': 'and',\n",
       "    'lemma': 'and',\n",
       "    'characterOffsetBegin': 7,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 3,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 11,\n",
       "    'characterOffsetEnd': 14,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'US',\n",
       "    'originalText': 'US',\n",
       "    'lemma': 'US',\n",
       "    'characterOffsetBegin': 15,\n",
       "    'characterOffsetEnd': 17,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'COUNTRY',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 5,\n",
       "    'word': 'have',\n",
       "    'originalText': 'have',\n",
       "    'lemma': 'have',\n",
       "    'characterOffsetBegin': 18,\n",
       "    'characterOffsetEnd': 22,\n",
       "    'pos': 'VBP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 6,\n",
       "    'word': 'warned',\n",
       "    'originalText': 'warned',\n",
       "    'lemma': 'warn',\n",
       "    'characterOffsetBegin': 23,\n",
       "    'characterOffsetEnd': 29,\n",
       "    'pos': 'VBN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 7,\n",
       "    'word': 'Iran',\n",
       "    'originalText': 'Iran',\n",
       "    'lemma': 'Iran',\n",
       "    'characterOffsetBegin': 30,\n",
       "    'characterOffsetEnd': 34,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'COUNTRY',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 8,\n",
       "    'word': 'against',\n",
       "    'originalText': 'against',\n",
       "    'lemma': 'against',\n",
       "    'characterOffsetBegin': 35,\n",
       "    'characterOffsetEnd': 42,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 9,\n",
       "    'word': 'reviving',\n",
       "    'originalText': 'reviving',\n",
       "    'lemma': 'revive',\n",
       "    'characterOffsetBegin': 43,\n",
       "    'characterOffsetEnd': 51,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 10,\n",
       "    'word': 'its',\n",
       "    'originalText': 'its',\n",
       "    'lemma': 'its',\n",
       "    'characterOffsetBegin': 52,\n",
       "    'characterOffsetEnd': 55,\n",
       "    'pos': 'PRP$',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 11,\n",
       "    'word': 'nuclear',\n",
       "    'originalText': 'nuclear',\n",
       "    'lemma': 'nuclear',\n",
       "    'characterOffsetBegin': 56,\n",
       "    'characterOffsetEnd': 63,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 12,\n",
       "    'word': 'programme',\n",
       "    'originalText': 'programme',\n",
       "    'lemma': 'programme',\n",
       "    'characterOffsetBegin': 64,\n",
       "    'characterOffsetEnd': 73,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 13,\n",
       "    'word': 'after',\n",
       "    'originalText': 'after',\n",
       "    'lemma': 'after',\n",
       "    'characterOffsetBegin': 74,\n",
       "    'characterOffsetEnd': 79,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 14,\n",
       "    'word': 'Tehran',\n",
       "    'originalText': 'Tehran',\n",
       "    'lemma': 'Tehran',\n",
       "    'characterOffsetBegin': 80,\n",
       "    'characterOffsetEnd': 86,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'LOCATION',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 15,\n",
       "    'word': 'said',\n",
       "    'originalText': 'said',\n",
       "    'lemma': 'say',\n",
       "    'characterOffsetBegin': 87,\n",
       "    'characterOffsetEnd': 91,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 16,\n",
       "    'word': 'it',\n",
       "    'originalText': 'it',\n",
       "    'lemma': 'it',\n",
       "    'characterOffsetBegin': 92,\n",
       "    'characterOffsetEnd': 94,\n",
       "    'pos': 'PRP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 17,\n",
       "    'word': 'would',\n",
       "    'originalText': 'would',\n",
       "    'lemma': 'would',\n",
       "    'characterOffsetBegin': 95,\n",
       "    'characterOffsetEnd': 100,\n",
       "    'pos': 'MD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 18,\n",
       "    'word': 'stop',\n",
       "    'originalText': 'stop',\n",
       "    'lemma': 'stop',\n",
       "    'characterOffsetBegin': 101,\n",
       "    'characterOffsetEnd': 105,\n",
       "    'pos': 'VB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 19,\n",
       "    'word': 'complying',\n",
       "    'originalText': 'complying',\n",
       "    'lemma': 'comply',\n",
       "    'characterOffsetBegin': 106,\n",
       "    'characterOffsetEnd': 115,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 20,\n",
       "    'word': 'with',\n",
       "    'originalText': 'with',\n",
       "    'lemma': 'with',\n",
       "    'characterOffsetBegin': 116,\n",
       "    'characterOffsetEnd': 120,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 21,\n",
       "    'word': 'parts',\n",
       "    'originalText': 'parts',\n",
       "    'lemma': 'part',\n",
       "    'characterOffsetBegin': 121,\n",
       "    'characterOffsetEnd': 126,\n",
       "    'pos': 'NNS',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 22,\n",
       "    'word': 'of',\n",
       "    'originalText': 'of',\n",
       "    'lemma': 'of',\n",
       "    'characterOffsetBegin': 127,\n",
       "    'characterOffsetEnd': 129,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 23,\n",
       "    'word': 'a',\n",
       "    'originalText': 'a',\n",
       "    'lemma': 'a',\n",
       "    'characterOffsetBegin': 130,\n",
       "    'characterOffsetEnd': 131,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 24,\n",
       "    'word': '2015',\n",
       "    'originalText': '2015',\n",
       "    'lemma': '2015',\n",
       "    'characterOffsetBegin': 132,\n",
       "    'characterOffsetEnd': 136,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'DATE',\n",
       "    'normalizedNER': '2015',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 25,\n",
       "    'word': 'atomic',\n",
       "    'originalText': 'atomic',\n",
       "    'lemma': 'atomic',\n",
       "    'characterOffsetBegin': 137,\n",
       "    'characterOffsetEnd': 143,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 26,\n",
       "    'word': 'deal',\n",
       "    'originalText': 'deal',\n",
       "    'lemma': 'deal',\n",
       "    'characterOffsetBegin': 144,\n",
       "    'characterOffsetEnd': 148,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 27,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 148,\n",
       "    'characterOffsetEnd': 149,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 28,\n",
       "    'word': 'raising',\n",
       "    'originalText': 'raising',\n",
       "    'lemma': 'raise',\n",
       "    'characterOffsetBegin': 150,\n",
       "    'characterOffsetEnd': 157,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 29,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 158,\n",
       "    'characterOffsetEnd': 161,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 30,\n",
       "    'word': 'stakes',\n",
       "    'originalText': 'stakes',\n",
       "    'lemma': 'stake',\n",
       "    'characterOffsetBegin': 162,\n",
       "    'characterOffsetEnd': 168,\n",
       "    'pos': 'NNS',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 31,\n",
       "    'word': 'in',\n",
       "    'originalText': 'in',\n",
       "    'lemma': 'in',\n",
       "    'characterOffsetBegin': 169,\n",
       "    'characterOffsetEnd': 171,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 32,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 172,\n",
       "    'characterOffsetEnd': 175,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 33,\n",
       "    'word': 'regime',\n",
       "    'originalText': 'regime',\n",
       "    'lemma': 'regime',\n",
       "    'characterOffsetBegin': 176,\n",
       "    'characterOffsetEnd': 182,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 34,\n",
       "    'word': \"'s\",\n",
       "    'originalText': '’s',\n",
       "    'lemma': \"'s\",\n",
       "    'characterOffsetBegin': 182,\n",
       "    'characterOffsetEnd': 184,\n",
       "    'pos': 'POS',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 35,\n",
       "    'word': 'stand-off',\n",
       "    'originalText': 'stand-off',\n",
       "    'lemma': 'stand-off',\n",
       "    'characterOffsetBegin': 185,\n",
       "    'characterOffsetEnd': 194,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 36,\n",
       "    'word': 'with',\n",
       "    'originalText': 'with',\n",
       "    'lemma': 'with',\n",
       "    'characterOffsetBegin': 195,\n",
       "    'characterOffsetEnd': 199,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 37,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 200,\n",
       "    'characterOffsetEnd': 203,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 38,\n",
       "    'word': 'Trump',\n",
       "    'originalText': 'Trump',\n",
       "    'lemma': 'Trump',\n",
       "    'characterOffsetBegin': 204,\n",
       "    'characterOffsetEnd': 209,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'PERSON',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 39,\n",
       "    'word': 'administration',\n",
       "    'originalText': 'administration',\n",
       "    'lemma': 'administration',\n",
       "    'characterOffsetBegin': 210,\n",
       "    'characterOffsetEnd': 224,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 40,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 224,\n",
       "    'characterOffsetEnd': 225,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ''}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Europe (LOCATION) and (O) the (O) US (COUNTRY) have (O) warned (O) Iran (COUNTRY) against (O) reviving (O) its (O) nuclear (O) programme (O) after (O) Tehran (LOCATION) said (O) it (O) would (O) stop (O) complying (O) with (O) parts (O) of (O) a (O) 2015 (DATE) atomic (O) deal (O) , (O) raising (O) the (O) stakes (O) in (O) the (O) regime (O) 's (O) stand-off (O) with (O) the (O) Trump (PERSON) administration (O) . (O)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = []\n",
    "for word in result2[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['ner']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have different NER labels:\n",
    "# Europe -- location, \n",
    "# US -- country, \n",
    "# Iran -- country,\n",
    "# 2015 -- date,\n",
    "# Trump -- person\n",
    "\n",
    "# try another example --- the open lines from Joseph Conrad's novel:\n",
    "\n",
    "text3 = \"The Nellie, a cruising yawl, swung to her anchor without a flutter of the sails, and was at rest. The flood had made, the wind was nearly calm, and being bound down the river, the only thing for it was to come to and wait for the turn of the tide.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = nlp.annotate(text3,\n",
    "                   properties={\n",
    "                       'annotators': 'ner, pos',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                   })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'entitymentions': [{'docTokenBegin': 1,\n",
       "    'docTokenEnd': 2,\n",
       "    'tokenBegin': 1,\n",
       "    'tokenEnd': 2,\n",
       "    'text': 'Nellie',\n",
       "    'characterOffsetBegin': 4,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'ner': 'PERSON',\n",
       "    'nerConfidences': {'PERSON': 0.7205367853984}},\n",
       "   {'docTokenBegin': 9,\n",
       "    'docTokenEnd': 10,\n",
       "    'tokenBegin': 9,\n",
       "    'tokenEnd': 10,\n",
       "    'text': 'her',\n",
       "    'characterOffsetBegin': 38,\n",
       "    'characterOffsetEnd': 41,\n",
       "    'ner': 'PERSON'}],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'The',\n",
       "    'originalText': 'The',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 3,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'Nellie',\n",
       "    'originalText': 'Nellie',\n",
       "    'lemma': 'Nellie',\n",
       "    'characterOffsetBegin': 4,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'pos': 'NNP',\n",
       "    'ner': 'PERSON',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 3,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 10,\n",
       "    'characterOffsetEnd': 11,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'a',\n",
       "    'originalText': 'a',\n",
       "    'lemma': 'a',\n",
       "    'characterOffsetBegin': 12,\n",
       "    'characterOffsetEnd': 13,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 5,\n",
       "    'word': 'cruising',\n",
       "    'originalText': 'cruising',\n",
       "    'lemma': 'cruise',\n",
       "    'characterOffsetBegin': 14,\n",
       "    'characterOffsetEnd': 22,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 6,\n",
       "    'word': 'yawl',\n",
       "    'originalText': 'yawl',\n",
       "    'lemma': 'yawl',\n",
       "    'characterOffsetBegin': 23,\n",
       "    'characterOffsetEnd': 27,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 7,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 27,\n",
       "    'characterOffsetEnd': 28,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 8,\n",
       "    'word': 'swung',\n",
       "    'originalText': 'swung',\n",
       "    'lemma': 'swing',\n",
       "    'characterOffsetBegin': 29,\n",
       "    'characterOffsetEnd': 34,\n",
       "    'pos': 'VBN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 9,\n",
       "    'word': 'to',\n",
       "    'originalText': 'to',\n",
       "    'lemma': 'to',\n",
       "    'characterOffsetBegin': 35,\n",
       "    'characterOffsetEnd': 37,\n",
       "    'pos': 'TO',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 10,\n",
       "    'word': 'her',\n",
       "    'originalText': 'her',\n",
       "    'lemma': 'she',\n",
       "    'characterOffsetBegin': 38,\n",
       "    'characterOffsetEnd': 41,\n",
       "    'pos': 'PRP$',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 11,\n",
       "    'word': 'anchor',\n",
       "    'originalText': 'anchor',\n",
       "    'lemma': 'anchor',\n",
       "    'characterOffsetBegin': 42,\n",
       "    'characterOffsetEnd': 48,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 12,\n",
       "    'word': 'without',\n",
       "    'originalText': 'without',\n",
       "    'lemma': 'without',\n",
       "    'characterOffsetBegin': 49,\n",
       "    'characterOffsetEnd': 56,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 13,\n",
       "    'word': 'a',\n",
       "    'originalText': 'a',\n",
       "    'lemma': 'a',\n",
       "    'characterOffsetBegin': 57,\n",
       "    'characterOffsetEnd': 58,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 14,\n",
       "    'word': 'flutter',\n",
       "    'originalText': 'flutter',\n",
       "    'lemma': 'flutter',\n",
       "    'characterOffsetBegin': 59,\n",
       "    'characterOffsetEnd': 66,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 15,\n",
       "    'word': 'of',\n",
       "    'originalText': 'of',\n",
       "    'lemma': 'of',\n",
       "    'characterOffsetBegin': 67,\n",
       "    'characterOffsetEnd': 69,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 16,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 70,\n",
       "    'characterOffsetEnd': 73,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 17,\n",
       "    'word': 'sails',\n",
       "    'originalText': 'sails',\n",
       "    'lemma': 'sail',\n",
       "    'characterOffsetBegin': 74,\n",
       "    'characterOffsetEnd': 79,\n",
       "    'pos': 'NNS',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 18,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 79,\n",
       "    'characterOffsetEnd': 80,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 19,\n",
       "    'word': 'and',\n",
       "    'originalText': 'and',\n",
       "    'lemma': 'and',\n",
       "    'characterOffsetBegin': 81,\n",
       "    'characterOffsetEnd': 84,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 20,\n",
       "    'word': 'was',\n",
       "    'originalText': 'was',\n",
       "    'lemma': 'be',\n",
       "    'characterOffsetBegin': 85,\n",
       "    'characterOffsetEnd': 88,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 21,\n",
       "    'word': 'at',\n",
       "    'originalText': 'at',\n",
       "    'lemma': 'at',\n",
       "    'characterOffsetBegin': 89,\n",
       "    'characterOffsetEnd': 91,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 22,\n",
       "    'word': 'rest',\n",
       "    'originalText': 'rest',\n",
       "    'lemma': 'rest',\n",
       "    'characterOffsetBegin': 92,\n",
       "    'characterOffsetEnd': 96,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 23,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 96,\n",
       "    'characterOffsetEnd': 97,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '}]},\n",
       " {'index': 1,\n",
       "  'entitymentions': [{'docTokenBegin': 24,\n",
       "    'docTokenEnd': 25,\n",
       "    'tokenBegin': 1,\n",
       "    'tokenEnd': 2,\n",
       "    'text': 'flood',\n",
       "    'characterOffsetBegin': 102,\n",
       "    'characterOffsetEnd': 107,\n",
       "    'ner': 'CAUSE_OF_DEATH'},\n",
       "   {'docTokenBegin': 39,\n",
       "    'docTokenEnd': 40,\n",
       "    'tokenBegin': 16,\n",
       "    'tokenEnd': 17,\n",
       "    'text': 'river',\n",
       "    'characterOffsetBegin': 169,\n",
       "    'characterOffsetEnd': 174,\n",
       "    'ner': 'TITLE'}],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': 'The',\n",
       "    'originalText': 'The',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 98,\n",
       "    'characterOffsetEnd': 101,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 2,\n",
       "    'word': 'flood',\n",
       "    'originalText': 'flood',\n",
       "    'lemma': 'flood',\n",
       "    'characterOffsetBegin': 102,\n",
       "    'characterOffsetEnd': 107,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'CAUSE_OF_DEATH',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 3,\n",
       "    'word': 'had',\n",
       "    'originalText': 'had',\n",
       "    'lemma': 'have',\n",
       "    'characterOffsetBegin': 108,\n",
       "    'characterOffsetEnd': 111,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 4,\n",
       "    'word': 'made',\n",
       "    'originalText': 'made',\n",
       "    'lemma': 'make',\n",
       "    'characterOffsetBegin': 112,\n",
       "    'characterOffsetEnd': 116,\n",
       "    'pos': 'VBN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 5,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 116,\n",
       "    'characterOffsetEnd': 117,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 6,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 118,\n",
       "    'characterOffsetEnd': 121,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 7,\n",
       "    'word': 'wind',\n",
       "    'originalText': 'wind',\n",
       "    'lemma': 'wind',\n",
       "    'characterOffsetBegin': 122,\n",
       "    'characterOffsetEnd': 126,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 8,\n",
       "    'word': 'was',\n",
       "    'originalText': 'was',\n",
       "    'lemma': 'be',\n",
       "    'characterOffsetBegin': 127,\n",
       "    'characterOffsetEnd': 130,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 9,\n",
       "    'word': 'nearly',\n",
       "    'originalText': 'nearly',\n",
       "    'lemma': 'nearly',\n",
       "    'characterOffsetBegin': 131,\n",
       "    'characterOffsetEnd': 137,\n",
       "    'pos': 'RB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 10,\n",
       "    'word': 'calm',\n",
       "    'originalText': 'calm',\n",
       "    'lemma': 'calm',\n",
       "    'characterOffsetBegin': 138,\n",
       "    'characterOffsetEnd': 142,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 11,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 142,\n",
       "    'characterOffsetEnd': 143,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 12,\n",
       "    'word': 'and',\n",
       "    'originalText': 'and',\n",
       "    'lemma': 'and',\n",
       "    'characterOffsetBegin': 144,\n",
       "    'characterOffsetEnd': 147,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 13,\n",
       "    'word': 'being',\n",
       "    'originalText': 'being',\n",
       "    'lemma': 'be',\n",
       "    'characterOffsetBegin': 148,\n",
       "    'characterOffsetEnd': 153,\n",
       "    'pos': 'VBG',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 14,\n",
       "    'word': 'bound',\n",
       "    'originalText': 'bound',\n",
       "    'lemma': 'bind',\n",
       "    'characterOffsetBegin': 154,\n",
       "    'characterOffsetEnd': 159,\n",
       "    'pos': 'VBN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 15,\n",
       "    'word': 'down',\n",
       "    'originalText': 'down',\n",
       "    'lemma': 'down',\n",
       "    'characterOffsetBegin': 160,\n",
       "    'characterOffsetEnd': 164,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 16,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 165,\n",
       "    'characterOffsetEnd': 168,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 17,\n",
       "    'word': 'river',\n",
       "    'originalText': 'river',\n",
       "    'lemma': 'river',\n",
       "    'characterOffsetBegin': 169,\n",
       "    'characterOffsetEnd': 174,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'TITLE',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 18,\n",
       "    'word': ',',\n",
       "    'originalText': ',',\n",
       "    'lemma': ',',\n",
       "    'characterOffsetBegin': 174,\n",
       "    'characterOffsetEnd': 175,\n",
       "    'pos': ',',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ' '},\n",
       "   {'index': 19,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 176,\n",
       "    'characterOffsetEnd': 179,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 20,\n",
       "    'word': 'only',\n",
       "    'originalText': 'only',\n",
       "    'lemma': 'only',\n",
       "    'characterOffsetBegin': 180,\n",
       "    'characterOffsetEnd': 184,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 21,\n",
       "    'word': 'thing',\n",
       "    'originalText': 'thing',\n",
       "    'lemma': 'thing',\n",
       "    'characterOffsetBegin': 185,\n",
       "    'characterOffsetEnd': 190,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 22,\n",
       "    'word': 'for',\n",
       "    'originalText': 'for',\n",
       "    'lemma': 'for',\n",
       "    'characterOffsetBegin': 191,\n",
       "    'characterOffsetEnd': 194,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 23,\n",
       "    'word': 'it',\n",
       "    'originalText': 'it',\n",
       "    'lemma': 'it',\n",
       "    'characterOffsetBegin': 195,\n",
       "    'characterOffsetEnd': 197,\n",
       "    'pos': 'PRP',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 24,\n",
       "    'word': 'was',\n",
       "    'originalText': 'was',\n",
       "    'lemma': 'be',\n",
       "    'characterOffsetBegin': 198,\n",
       "    'characterOffsetEnd': 201,\n",
       "    'pos': 'VBD',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 25,\n",
       "    'word': 'to',\n",
       "    'originalText': 'to',\n",
       "    'lemma': 'to',\n",
       "    'characterOffsetBegin': 202,\n",
       "    'characterOffsetEnd': 204,\n",
       "    'pos': 'TO',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 26,\n",
       "    'word': 'come',\n",
       "    'originalText': 'come',\n",
       "    'lemma': 'come',\n",
       "    'characterOffsetBegin': 205,\n",
       "    'characterOffsetEnd': 209,\n",
       "    'pos': 'VB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 27,\n",
       "    'word': 'to',\n",
       "    'originalText': 'to',\n",
       "    'lemma': 'to',\n",
       "    'characterOffsetBegin': 210,\n",
       "    'characterOffsetEnd': 212,\n",
       "    'pos': 'TO',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 28,\n",
       "    'word': 'and',\n",
       "    'originalText': 'and',\n",
       "    'lemma': 'and',\n",
       "    'characterOffsetBegin': 213,\n",
       "    'characterOffsetEnd': 216,\n",
       "    'pos': 'CC',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 29,\n",
       "    'word': 'wait',\n",
       "    'originalText': 'wait',\n",
       "    'lemma': 'wait',\n",
       "    'characterOffsetBegin': 217,\n",
       "    'characterOffsetEnd': 221,\n",
       "    'pos': 'VB',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 30,\n",
       "    'word': 'for',\n",
       "    'originalText': 'for',\n",
       "    'lemma': 'for',\n",
       "    'characterOffsetBegin': 222,\n",
       "    'characterOffsetEnd': 225,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 31,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 226,\n",
       "    'characterOffsetEnd': 229,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 32,\n",
       "    'word': 'turn',\n",
       "    'originalText': 'turn',\n",
       "    'lemma': 'turn',\n",
       "    'characterOffsetBegin': 230,\n",
       "    'characterOffsetEnd': 234,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 33,\n",
       "    'word': 'of',\n",
       "    'originalText': 'of',\n",
       "    'lemma': 'of',\n",
       "    'characterOffsetBegin': 235,\n",
       "    'characterOffsetEnd': 237,\n",
       "    'pos': 'IN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 34,\n",
       "    'word': 'the',\n",
       "    'originalText': 'the',\n",
       "    'lemma': 'the',\n",
       "    'characterOffsetBegin': 238,\n",
       "    'characterOffsetEnd': 241,\n",
       "    'pos': 'DT',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ' '},\n",
       "   {'index': 35,\n",
       "    'word': 'tide',\n",
       "    'originalText': 'tide',\n",
       "    'lemma': 'tide',\n",
       "    'characterOffsetBegin': 242,\n",
       "    'characterOffsetEnd': 246,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O',\n",
       "    'before': ' ',\n",
       "    'after': ''},\n",
       "   {'index': 36,\n",
       "    'word': '.',\n",
       "    'originalText': '.',\n",
       "    'lemma': '.',\n",
       "    'characterOffsetBegin': 246,\n",
       "    'characterOffsetEnd': 247,\n",
       "    'pos': '.',\n",
       "    'ner': 'O',\n",
       "    'before': '',\n",
       "    'after': ''}]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The (O) Nellie (PERSON) , (O) a (O) cruising (O) yawl (O) , (O) swung (O) to (O) her (O) anchor (O) without (O) a (O) flutter (O) of (O) the (O) sails (O) , (O) and (O) was (O) at (O) rest (O) . (O)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the NER labels\n",
    "\n",
    "pos = []\n",
    "for word in result3[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['ner']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The (DT) Nellie (NNP) , (,) a (DT) cruising (VBG) yawl (NN) , (,) swung (VBN) to (TO) her (PRP$) anchor (NN) without (IN) a (DT) flutter (NN) of (IN) the (DT) sails (NNS) , (,) and (CC) was (VBD) at (IN) rest (NN) . (.)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the pos taggers\n",
    "\n",
    "pos = []\n",
    "for word in result3[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['pos']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a server using Chinese properties:\n",
    "\n",
    "``` bash\n",
    "java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -serverProperties StanfordCoreNLP-chinese.properties -port 9000 -timeout 15000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ch = \"新华社福州5月8日电（记者余俊杰、颜之宏）记者从8日闭幕的第二届数字中国建设峰会上获悉，为期3天的峰会共对接数字经济项目587项，总投资额4569亿元，其中签约项目308项，总投资额2520亿元。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ch = nlp.annotate(text_ch,\n",
    "                   properties={\n",
    "                       'annotators': 'ner, pos',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                   })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'entitymentions': [{'docTokenBegin': 0,\n",
       "    'docTokenEnd': 1,\n",
       "    'tokenBegin': 0,\n",
       "    'tokenEnd': 1,\n",
       "    'text': '新华社',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 3,\n",
       "    'ner': 'ORGANIZATION',\n",
       "    'nerConfidences': {'ORGANIZATION': 0.99933014808887}},\n",
       "   {'docTokenBegin': 1,\n",
       "    'docTokenEnd': 2,\n",
       "    'tokenBegin': 1,\n",
       "    'tokenEnd': 2,\n",
       "    'text': '福州',\n",
       "    'characterOffsetBegin': 3,\n",
       "    'characterOffsetEnd': 5,\n",
       "    'ner': 'CITY',\n",
       "    'nerConfidences': {'GPE': 0.99824373714923}},\n",
       "   {'docTokenBegin': 2,\n",
       "    'docTokenEnd': 4,\n",
       "    'tokenBegin': 2,\n",
       "    'tokenEnd': 4,\n",
       "    'text': '5月8日',\n",
       "    'characterOffsetBegin': 5,\n",
       "    'characterOffsetEnd': 9,\n",
       "    'ner': 'DATE',\n",
       "    'normalizedNER': 'XXXX-05-08',\n",
       "    'nerConfidences': {'DATE': 0.99757596733706}},\n",
       "   {'docTokenBegin': 6,\n",
       "    'docTokenEnd': 7,\n",
       "    'tokenBegin': 6,\n",
       "    'tokenEnd': 7,\n",
       "    'text': '记者',\n",
       "    'characterOffsetBegin': 11,\n",
       "    'characterOffsetEnd': 13,\n",
       "    'ner': 'TITLE'},\n",
       "   {'docTokenBegin': 7,\n",
       "    'docTokenEnd': 8,\n",
       "    'tokenBegin': 7,\n",
       "    'tokenEnd': 8,\n",
       "    'text': '余俊杰',\n",
       "    'characterOffsetBegin': 13,\n",
       "    'characterOffsetEnd': 16,\n",
       "    'ner': 'PERSON',\n",
       "    'nerConfidences': {'PERSON': 0.99643624697441}},\n",
       "   {'docTokenBegin': 9,\n",
       "    'docTokenEnd': 10,\n",
       "    'tokenBegin': 9,\n",
       "    'tokenEnd': 10,\n",
       "    'text': '颜之宏',\n",
       "    'characterOffsetBegin': 17,\n",
       "    'characterOffsetEnd': 20,\n",
       "    'ner': 'PERSON',\n",
       "    'nerConfidences': {'PERSON': 0.99216035308978}},\n",
       "   {'docTokenBegin': 11,\n",
       "    'docTokenEnd': 12,\n",
       "    'tokenBegin': 11,\n",
       "    'tokenEnd': 12,\n",
       "    'text': '记者',\n",
       "    'characterOffsetBegin': 21,\n",
       "    'characterOffsetEnd': 23,\n",
       "    'ner': 'TITLE'},\n",
       "   {'docTokenBegin': 13,\n",
       "    'docTokenEnd': 14,\n",
       "    'tokenBegin': 13,\n",
       "    'tokenEnd': 14,\n",
       "    'text': '8',\n",
       "    'characterOffsetBegin': 24,\n",
       "    'characterOffsetEnd': 25,\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '8',\n",
       "    'nerConfidences': {'NUMBER': 0.95992111831121}},\n",
       "   {'docTokenBegin': 14,\n",
       "    'docTokenEnd': 15,\n",
       "    'tokenBegin': 14,\n",
       "    'tokenEnd': 15,\n",
       "    'text': '日',\n",
       "    'characterOffsetBegin': 25,\n",
       "    'characterOffsetEnd': 26,\n",
       "    'ner': 'MISC',\n",
       "    'nerConfidences': {'MISC': 0.94892777752656}},\n",
       "   {'docTokenBegin': 17,\n",
       "    'docTokenEnd': 18,\n",
       "    'tokenBegin': 17,\n",
       "    'tokenEnd': 18,\n",
       "    'text': '第二',\n",
       "    'characterOffsetBegin': 29,\n",
       "    'characterOffsetEnd': 31,\n",
       "    'ner': 'ORDINAL',\n",
       "    'normalizedNER': '2',\n",
       "    'nerConfidences': {'ORDINAL': 0.99400151388489}},\n",
       "   {'docTokenBegin': 18,\n",
       "    'docTokenEnd': 23,\n",
       "    'tokenBegin': 18,\n",
       "    'tokenEnd': 23,\n",
       "    'text': '届数字中国建设峰会',\n",
       "    'characterOffsetBegin': 31,\n",
       "    'characterOffsetEnd': 40,\n",
       "    'ner': 'MISC',\n",
       "    'nerConfidences': {'MISC': 0.67464072466682}},\n",
       "   {'docTokenBegin': 27,\n",
       "    'docTokenEnd': 28,\n",
       "    'tokenBegin': 27,\n",
       "    'tokenEnd': 28,\n",
       "    'text': '3',\n",
       "    'characterOffsetBegin': 46,\n",
       "    'characterOffsetEnd': 47,\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '3',\n",
       "    'nerConfidences': {'NUMBER': 0.99999161252122}},\n",
       "   {'docTokenBegin': 28,\n",
       "    'docTokenEnd': 31,\n",
       "    'tokenBegin': 28,\n",
       "    'tokenEnd': 31,\n",
       "    'text': '天的峰会',\n",
       "    'characterOffsetBegin': 47,\n",
       "    'characterOffsetEnd': 51,\n",
       "    'ner': 'MISC',\n",
       "    'nerConfidences': {'MISC': 0.58652504624601}},\n",
       "   {'docTokenBegin': 36,\n",
       "    'docTokenEnd': 37,\n",
       "    'tokenBegin': 36,\n",
       "    'tokenEnd': 37,\n",
       "    'text': '587',\n",
       "    'characterOffsetBegin': 60,\n",
       "    'characterOffsetEnd': 63,\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '587',\n",
       "    'nerConfidences': {'NUMBER': 0.875844369215}},\n",
       "   {'docTokenBegin': 37,\n",
       "    'docTokenEnd': 38,\n",
       "    'tokenBegin': 37,\n",
       "    'tokenEnd': 38,\n",
       "    'text': '项',\n",
       "    'characterOffsetBegin': 63,\n",
       "    'characterOffsetEnd': 64,\n",
       "    'ner': 'MISC',\n",
       "    'nerConfidences': {'MISC': 0.52047318481747}},\n",
       "   {'docTokenBegin': 41,\n",
       "    'docTokenEnd': 43,\n",
       "    'tokenBegin': 41,\n",
       "    'tokenEnd': 43,\n",
       "    'text': '4569亿元',\n",
       "    'characterOffsetBegin': 69,\n",
       "    'characterOffsetEnd': 75,\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元456900000000',\n",
       "    'nerConfidences': {'MONEY': 0.99952661882471}},\n",
       "   {'docTokenBegin': 47,\n",
       "    'docTokenEnd': 48,\n",
       "    'tokenBegin': 47,\n",
       "    'tokenEnd': 48,\n",
       "    'text': '308',\n",
       "    'characterOffsetBegin': 82,\n",
       "    'characterOffsetEnd': 85,\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '308',\n",
       "    'nerConfidences': {'NUMBER': 0.80415812202179}},\n",
       "   {'docTokenBegin': 48,\n",
       "    'docTokenEnd': 49,\n",
       "    'tokenBegin': 48,\n",
       "    'tokenEnd': 49,\n",
       "    'text': '项',\n",
       "    'characterOffsetBegin': 85,\n",
       "    'characterOffsetEnd': 86,\n",
       "    'ner': 'MISC',\n",
       "    'nerConfidences': {'MISC': 0.6087413688713}},\n",
       "   {'docTokenBegin': 52,\n",
       "    'docTokenEnd': 54,\n",
       "    'tokenBegin': 52,\n",
       "    'tokenEnd': 54,\n",
       "    'text': '2520亿元',\n",
       "    'characterOffsetBegin': 91,\n",
       "    'characterOffsetEnd': 97,\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元252000000000',\n",
       "    'nerConfidences': {'MONEY': 0.99660842029871}}],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': '新华社',\n",
       "    'originalText': '新华社',\n",
       "    'lemma': '新华社',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 3,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'ORGANIZATION'},\n",
       "   {'index': 2,\n",
       "    'word': '福州',\n",
       "    'originalText': '福州',\n",
       "    'lemma': '福州',\n",
       "    'characterOffsetBegin': 3,\n",
       "    'characterOffsetEnd': 5,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'CITY'},\n",
       "   {'index': 3,\n",
       "    'word': '5月',\n",
       "    'originalText': '5月',\n",
       "    'lemma': '5月',\n",
       "    'characterOffsetBegin': 5,\n",
       "    'characterOffsetEnd': 7,\n",
       "    'pos': 'NT',\n",
       "    'ner': 'DATE',\n",
       "    'normalizedNER': 'XXXX-05-08'},\n",
       "   {'index': 4,\n",
       "    'word': '8日',\n",
       "    'originalText': '8日',\n",
       "    'lemma': '8日',\n",
       "    'characterOffsetBegin': 7,\n",
       "    'characterOffsetEnd': 9,\n",
       "    'pos': 'NT',\n",
       "    'ner': 'DATE',\n",
       "    'normalizedNER': 'XXXX-05-08'},\n",
       "   {'index': 5,\n",
       "    'word': '电',\n",
       "    'originalText': '电',\n",
       "    'lemma': '电',\n",
       "    'characterOffsetBegin': 9,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 6,\n",
       "    'word': '（',\n",
       "    'originalText': '（',\n",
       "    'lemma': '（',\n",
       "    'characterOffsetBegin': 10,\n",
       "    'characterOffsetEnd': 11,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 7,\n",
       "    'word': '记者',\n",
       "    'originalText': '记者',\n",
       "    'lemma': '记者',\n",
       "    'characterOffsetBegin': 11,\n",
       "    'characterOffsetEnd': 13,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'TITLE'},\n",
       "   {'index': 8,\n",
       "    'word': '余俊杰',\n",
       "    'originalText': '余俊杰',\n",
       "    'lemma': '余俊杰',\n",
       "    'characterOffsetBegin': 13,\n",
       "    'characterOffsetEnd': 16,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'PERSON'},\n",
       "   {'index': 9,\n",
       "    'word': '、',\n",
       "    'originalText': '、',\n",
       "    'lemma': '、',\n",
       "    'characterOffsetBegin': 16,\n",
       "    'characterOffsetEnd': 17,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 10,\n",
       "    'word': '颜之宏',\n",
       "    'originalText': '颜之宏',\n",
       "    'lemma': '颜之宏',\n",
       "    'characterOffsetBegin': 17,\n",
       "    'characterOffsetEnd': 20,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'PERSON'},\n",
       "   {'index': 11,\n",
       "    'word': '）',\n",
       "    'originalText': '）',\n",
       "    'lemma': '）',\n",
       "    'characterOffsetBegin': 20,\n",
       "    'characterOffsetEnd': 21,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 12,\n",
       "    'word': '记者',\n",
       "    'originalText': '记者',\n",
       "    'lemma': '记者',\n",
       "    'characterOffsetBegin': 21,\n",
       "    'characterOffsetEnd': 23,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'TITLE'},\n",
       "   {'index': 13,\n",
       "    'word': '从',\n",
       "    'originalText': '从',\n",
       "    'lemma': '从',\n",
       "    'characterOffsetBegin': 23,\n",
       "    'characterOffsetEnd': 24,\n",
       "    'pos': 'P',\n",
       "    'ner': 'O'},\n",
       "   {'index': 14,\n",
       "    'word': '8',\n",
       "    'originalText': '8',\n",
       "    'lemma': '8',\n",
       "    'characterOffsetBegin': 24,\n",
       "    'characterOffsetEnd': 25,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '8'},\n",
       "   {'index': 15,\n",
       "    'word': '日',\n",
       "    'originalText': '日',\n",
       "    'lemma': '日',\n",
       "    'characterOffsetBegin': 25,\n",
       "    'characterOffsetEnd': 26,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 16,\n",
       "    'word': '闭幕',\n",
       "    'originalText': '闭幕',\n",
       "    'lemma': '闭幕',\n",
       "    'characterOffsetBegin': 26,\n",
       "    'characterOffsetEnd': 28,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 17,\n",
       "    'word': '的',\n",
       "    'originalText': '的',\n",
       "    'lemma': '的',\n",
       "    'characterOffsetBegin': 28,\n",
       "    'characterOffsetEnd': 29,\n",
       "    'pos': 'DEC',\n",
       "    'ner': 'O'},\n",
       "   {'index': 18,\n",
       "    'word': '第二',\n",
       "    'originalText': '第二',\n",
       "    'lemma': '第二',\n",
       "    'characterOffsetBegin': 29,\n",
       "    'characterOffsetEnd': 31,\n",
       "    'pos': 'OD',\n",
       "    'ner': 'ORDINAL',\n",
       "    'normalizedNER': '2'},\n",
       "   {'index': 19,\n",
       "    'word': '届',\n",
       "    'originalText': '届',\n",
       "    'lemma': '届',\n",
       "    'characterOffsetBegin': 31,\n",
       "    'characterOffsetEnd': 32,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 20,\n",
       "    'word': '数字',\n",
       "    'originalText': '数字',\n",
       "    'lemma': '数字',\n",
       "    'characterOffsetBegin': 32,\n",
       "    'characterOffsetEnd': 34,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 21,\n",
       "    'word': '中国',\n",
       "    'originalText': '中国',\n",
       "    'lemma': '中国',\n",
       "    'characterOffsetBegin': 34,\n",
       "    'characterOffsetEnd': 36,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 22,\n",
       "    'word': '建设',\n",
       "    'originalText': '建设',\n",
       "    'lemma': '建设',\n",
       "    'characterOffsetBegin': 36,\n",
       "    'characterOffsetEnd': 38,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 23,\n",
       "    'word': '峰会',\n",
       "    'originalText': '峰会',\n",
       "    'lemma': '峰会',\n",
       "    'characterOffsetBegin': 38,\n",
       "    'characterOffsetEnd': 40,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 24,\n",
       "    'word': '上',\n",
       "    'originalText': '上',\n",
       "    'lemma': '上',\n",
       "    'characterOffsetBegin': 40,\n",
       "    'characterOffsetEnd': 41,\n",
       "    'pos': 'LC',\n",
       "    'ner': 'O'},\n",
       "   {'index': 25,\n",
       "    'word': '获悉',\n",
       "    'originalText': '获悉',\n",
       "    'lemma': '获悉',\n",
       "    'characterOffsetBegin': 41,\n",
       "    'characterOffsetEnd': 43,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 26,\n",
       "    'word': '，',\n",
       "    'originalText': '，',\n",
       "    'lemma': '，',\n",
       "    'characterOffsetBegin': 43,\n",
       "    'characterOffsetEnd': 44,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 27,\n",
       "    'word': '为期',\n",
       "    'originalText': '为期',\n",
       "    'lemma': '为期',\n",
       "    'characterOffsetBegin': 44,\n",
       "    'characterOffsetEnd': 46,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 28,\n",
       "    'word': '3',\n",
       "    'originalText': '3',\n",
       "    'lemma': '3',\n",
       "    'characterOffsetBegin': 46,\n",
       "    'characterOffsetEnd': 47,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '3'},\n",
       "   {'index': 29,\n",
       "    'word': '天',\n",
       "    'originalText': '天',\n",
       "    'lemma': '天',\n",
       "    'characterOffsetBegin': 47,\n",
       "    'characterOffsetEnd': 48,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 30,\n",
       "    'word': '的',\n",
       "    'originalText': '的',\n",
       "    'lemma': '的',\n",
       "    'characterOffsetBegin': 48,\n",
       "    'characterOffsetEnd': 49,\n",
       "    'pos': 'DEC',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 31,\n",
       "    'word': '峰会',\n",
       "    'originalText': '峰会',\n",
       "    'lemma': '峰会',\n",
       "    'characterOffsetBegin': 49,\n",
       "    'characterOffsetEnd': 51,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 32,\n",
       "    'word': '共',\n",
       "    'originalText': '共',\n",
       "    'lemma': '共',\n",
       "    'characterOffsetBegin': 51,\n",
       "    'characterOffsetEnd': 52,\n",
       "    'pos': 'AD',\n",
       "    'ner': 'O'},\n",
       "   {'index': 33,\n",
       "    'word': '对接',\n",
       "    'originalText': '对接',\n",
       "    'lemma': '对接',\n",
       "    'characterOffsetBegin': 52,\n",
       "    'characterOffsetEnd': 54,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 34,\n",
       "    'word': '数字',\n",
       "    'originalText': '数字',\n",
       "    'lemma': '数字',\n",
       "    'characterOffsetBegin': 54,\n",
       "    'characterOffsetEnd': 56,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 35,\n",
       "    'word': '经济',\n",
       "    'originalText': '经济',\n",
       "    'lemma': '经济',\n",
       "    'characterOffsetBegin': 56,\n",
       "    'characterOffsetEnd': 58,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 36,\n",
       "    'word': '项目',\n",
       "    'originalText': '项目',\n",
       "    'lemma': '项目',\n",
       "    'characterOffsetBegin': 58,\n",
       "    'characterOffsetEnd': 60,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 37,\n",
       "    'word': '587',\n",
       "    'originalText': '587',\n",
       "    'lemma': '587',\n",
       "    'characterOffsetBegin': 60,\n",
       "    'characterOffsetEnd': 63,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '587'},\n",
       "   {'index': 38,\n",
       "    'word': '项',\n",
       "    'originalText': '项',\n",
       "    'lemma': '项',\n",
       "    'characterOffsetBegin': 63,\n",
       "    'characterOffsetEnd': 64,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 39,\n",
       "    'word': '，',\n",
       "    'originalText': '，',\n",
       "    'lemma': '，',\n",
       "    'characterOffsetBegin': 64,\n",
       "    'characterOffsetEnd': 65,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 40,\n",
       "    'word': '总',\n",
       "    'originalText': '总',\n",
       "    'lemma': '总',\n",
       "    'characterOffsetBegin': 65,\n",
       "    'characterOffsetEnd': 66,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O'},\n",
       "   {'index': 41,\n",
       "    'word': '投资额',\n",
       "    'originalText': '投资额',\n",
       "    'lemma': '投资额',\n",
       "    'characterOffsetBegin': 66,\n",
       "    'characterOffsetEnd': 69,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 42,\n",
       "    'word': '4569亿',\n",
       "    'originalText': '4569亿',\n",
       "    'lemma': '4569亿',\n",
       "    'characterOffsetBegin': 69,\n",
       "    'characterOffsetEnd': 74,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元456900000000'},\n",
       "   {'index': 43,\n",
       "    'word': '元',\n",
       "    'originalText': '元',\n",
       "    'lemma': '元',\n",
       "    'characterOffsetBegin': 74,\n",
       "    'characterOffsetEnd': 75,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元456900000000'},\n",
       "   {'index': 44,\n",
       "    'word': '，',\n",
       "    'originalText': '，',\n",
       "    'lemma': '，',\n",
       "    'characterOffsetBegin': 75,\n",
       "    'characterOffsetEnd': 76,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 45,\n",
       "    'word': '其中',\n",
       "    'originalText': '其中',\n",
       "    'lemma': '其中',\n",
       "    'characterOffsetBegin': 76,\n",
       "    'characterOffsetEnd': 78,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 46,\n",
       "    'word': '签约',\n",
       "    'originalText': '签约',\n",
       "    'lemma': '签约',\n",
       "    'characterOffsetBegin': 78,\n",
       "    'characterOffsetEnd': 80,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 47,\n",
       "    'word': '项目',\n",
       "    'originalText': '项目',\n",
       "    'lemma': '项目',\n",
       "    'characterOffsetBegin': 80,\n",
       "    'characterOffsetEnd': 82,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 48,\n",
       "    'word': '308',\n",
       "    'originalText': '308',\n",
       "    'lemma': '308',\n",
       "    'characterOffsetBegin': 82,\n",
       "    'characterOffsetEnd': 85,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'NUMBER',\n",
       "    'normalizedNER': '308'},\n",
       "   {'index': 49,\n",
       "    'word': '项',\n",
       "    'originalText': '项',\n",
       "    'lemma': '项',\n",
       "    'characterOffsetBegin': 85,\n",
       "    'characterOffsetEnd': 86,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MISC'},\n",
       "   {'index': 50,\n",
       "    'word': '，',\n",
       "    'originalText': '，',\n",
       "    'lemma': '，',\n",
       "    'characterOffsetBegin': 86,\n",
       "    'characterOffsetEnd': 87,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'},\n",
       "   {'index': 51,\n",
       "    'word': '总',\n",
       "    'originalText': '总',\n",
       "    'lemma': '总',\n",
       "    'characterOffsetBegin': 87,\n",
       "    'characterOffsetEnd': 88,\n",
       "    'pos': 'JJ',\n",
       "    'ner': 'O'},\n",
       "   {'index': 52,\n",
       "    'word': '投资额',\n",
       "    'originalText': '投资额',\n",
       "    'lemma': '投资额',\n",
       "    'characterOffsetBegin': 88,\n",
       "    'characterOffsetEnd': 91,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 53,\n",
       "    'word': '2520亿',\n",
       "    'originalText': '2520亿',\n",
       "    'lemma': '2520亿',\n",
       "    'characterOffsetBegin': 91,\n",
       "    'characterOffsetEnd': 96,\n",
       "    'pos': 'CD',\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元252000000000'},\n",
       "   {'index': 54,\n",
       "    'word': '元',\n",
       "    'originalText': '元',\n",
       "    'lemma': '元',\n",
       "    'characterOffsetBegin': 96,\n",
       "    'characterOffsetEnd': 97,\n",
       "    'pos': 'M',\n",
       "    'ner': 'MONEY',\n",
       "    'normalizedNER': '元252000000000'},\n",
       "   {'index': 55,\n",
       "    'word': '。',\n",
       "    'originalText': '。',\n",
       "    'lemma': '。',\n",
       "    'characterOffsetBegin': 97,\n",
       "    'characterOffsetEnd': 98,\n",
       "    'pos': 'PU',\n",
       "    'ner': 'O'}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ch['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新华社 (ORGANIZATION) 福州 (CITY) 5月 (DATE) 8日 (DATE) 电 (O) （ (O) 记者 (TITLE) 余俊杰 (PERSON) 、 (O) 颜之宏 (PERSON) ） (O) 记者 (TITLE) 从 (O) 8 (NUMBER) 日 (MISC) 闭幕 (O) 的 (O) 第二 (ORDINAL) 届 (MISC) 数字 (MISC) 中国 (MISC) 建设 (MISC) 峰会 (MISC) 上 (O) 获悉 (O) ， (O) 为期 (O) 3 (NUMBER) 天 (MISC) 的 (MISC) 峰会 (MISC) 共 (O) 对接 (O) 数字 (O) 经济 (O) 项目 (O) 587 (NUMBER) 项 (MISC) ， (O) 总 (O) 投资额 (O) 4569亿 (MONEY) 元 (MONEY) ， (O) 其中 (O) 签约 (O) 项目 (O) 308 (NUMBER) 项 (MISC) ， (O) 总 (O) 投资额 (O) 2520亿 (MONEY) 元 (MONEY) 。 (O)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the NER labels\n",
    "\n",
    "pos = []\n",
    "for word in result_ch[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['ner']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新华社 (NR) 福州 (NR) 5月 (NT) 8日 (NT) 电 (NN) （ (PU) 记者 (NN) 余俊杰 (NR) 、 (PU) 颜之宏 (NR) ） (PU) 记者 (NN) 从 (P) 8 (CD) 日 (M) 闭幕 (VV) 的 (DEC) 第二 (OD) 届 (M) 数字 (NN) 中国 (NR) 建设 (VV) 峰会 (NN) 上 (LC) 获悉 (VV) ， (PU) 为期 (VV) 3 (CD) 天 (M) 的 (DEC) 峰会 (NN) 共 (AD) 对接 (VV) 数字 (NN) 经济 (NN) 项目 (NN) 587 (CD) 项 (M) ， (PU) 总 (JJ) 投资额 (NN) 4569亿 (CD) 元 (M) ， (PU) 其中 (NN) 签约 (VV) 项目 (NN) 308 (CD) 项 (M) ， (PU) 总 (JJ) 投资额 (NN) 2520亿 (CD) 元 (M) 。 (PU)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the POS taggers\n",
    "\n",
    "pos = []\n",
    "for word in result_ch[\"sentences\"][0]['tokens']:\n",
    "    pos.append('{} ({})'.format(word['word'], word['pos']))\n",
    "    \n",
    "\" \".join(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
